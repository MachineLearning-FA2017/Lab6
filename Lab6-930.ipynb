{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "%load_ext memory_profiler\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.special import expit\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from memory_profiler import memory_usage\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "target_classifier = 'PC'\n",
    "df = pd.read_csv('responses.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove rows whose target classfier value is NaN\n",
    "df_cleaned_classifier = df[np.isfinite(df[target_classifier])]\n",
    "# change NaN number values to the mean\n",
    "df_imputed = df_cleaned_classifier.fillna(df.mean())\n",
    "# get categorical features\n",
    "object_features = list(df_cleaned_classifier.select_dtypes(include=['object']).columns)\n",
    "# one hot encode categorical features\n",
    "one_hot_df = pd.concat([pd.get_dummies(df_imputed[col],prefix=col) for col in object_features], axis=1)\n",
    "# drop object features from imputed dataframe\n",
    "df_imputed_dropped = df_imputed.drop(object_features, 1)\n",
    "frames = [df_imputed_dropped, one_hot_df]\n",
    "# concatenate both frames by columns\n",
    "df_fixed = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(get_confusion_costTot, greater_is_better=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Research on Cost Matrix\n",
    "# http://www.ibm.com/support/knowledgecenter/SSEPGG_11.1.0/com.ibm.im.model.doc/c_cost_matrix.html\n",
    "\n",
    "cost_matrix = np.matrix([[0,1,2,3,4],\n",
    "[1,0,1,2,3],\n",
    "[3,1,0,1,2],\n",
    "[5,3,1,0,1],\n",
    "[7,5,2,1,0]])\n",
    "\n",
    "def get_confusion_costTot(confusion_matrix, cost_matrix):\n",
    "    score = np.sum(confusion_matrix*cost_matrix)\n",
    "    return score\n",
    "\n",
    "confusion_scorer = make_scorer(get_confusion_costTot, greater_is_better=False)\n",
    "confusion_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if target_classifier in df_fixed:\n",
    "    y = df_fixed[target_classifier].values # get the labels we want\n",
    "    del df_fixed[target_classifier] # get rid of the class label\n",
    "    X = df_fixed.values # use everything else to predict!\n",
    "\n",
    "X = X/5\n",
    "num_folds = 10\n",
    "\n",
    "cv_object = StratifiedKFold(n_splits= num_folds, random_state=None, shuffle=True)\n",
    "cv_object.split(X,y)\n",
    "\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "        # I will create new variables here so that it is more obvious what \n",
    "        # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "        # but it makes this code less readable)\n",
    "        X_train = (X[train_indices])\n",
    "        y_train = y[train_indices]\n",
    "\n",
    "    #     print(X_train)\n",
    "    #     print(y_train)\n",
    "\n",
    "        X_test = (X[test_indices])\n",
    "        y_test = y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "clf = MLPClassifier() # adam numerical stabilizer\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "class MyEnsemble():\n",
    "    \n",
    "    def __init__(self, c, num_c, max_s, v):\n",
    "        self.Ensemble = BaggingClassifier(base_estimator= c,\n",
    "                                    n_estimators = num_c,\n",
    "                                     max_samples = max_s,\n",
    "                                     verbose = v)\n",
    "    def predict(self, X):\n",
    "        return self.Ensemble.predict(X)\n",
    "    \n",
    "    def fit(self, X,y):\n",
    "        return self.Ensemble.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  2.  5.  2.  3.  2.  3.  2.  5.  2.  5.  2.  5.  2.  5.  2.  4.  2.\n",
      "  2.  2.  3.  2.  2.  2.  3.  5.  5.  2.  2.  5.  3.  5.  5.  3.  3.  2.\n",
      "  3.  3.  2.  2.  3.  2.  3.  5.  3.  2.  5.  3.  5.  5.  2.  2.  5.  2.\n",
      "  2.  2.  3.  3.  2.  5.  5.  2.  4.  2.  2.  2.  5.  2.  5.  5.  3.  5.\n",
      "  2.  2.  5.  2.  5.  2.  5.  5.  2.  2.  3.  5.  2.  2.  5.  5.  2.  3.\n",
      "  2.  3.  5.  2.  2.  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "num_instances = 20\n",
    "\n",
    "\n",
    "ensemble = MyEnsemble(clf, num_instances,100,False)\n",
    "\n",
    "ensemble.fit(X_train,y_train)\n",
    "y_hat=ensemble.predict(X_test)\n",
    "print(y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  5.,  2.,  3.,  1.,  3.,  2.,  5.,  3.,  2.,  4.,  5.,\n",
       "        5.,  3.,  5.,  4.,  1.,  5.,  3.,  3.,  5.,  4.,  2.,  1.,  5.,\n",
       "        4.,  2.,  5.,  5.,  2.,  5.,  4.,  5.,  3.,  1.,  3.,  2.,  4.,\n",
       "        4.,  1.,  2.,  1.,  3.,  5.,  5.,  4.,  2.,  3.,  3.,  2.,  2.,\n",
       "        4.,  1.,  5.,  1.,  3.,  3.,  2.,  4.,  5.,  3.,  3.,  3.,  1.,\n",
       "        4.,  5.,  4.,  4.,  3.,  3.,  4.,  2.,  3.,  4.,  4.,  5.,  2.,\n",
       "        2.,  3.,  3.,  2.,  2.,  3.,  4.,  1.,  4.,  5.,  1.,  4.,  4.,\n",
       "        2.,  3.,  3.,  5.,  1.,  3.,  2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False,  True, False, False,  True, False,  True, False,\n",
       "        True, False,  True, False,  True, False, False,  True, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False,  True,  True,  True, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "        True, False, False, False,  True,  True, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr,thresholds = roc_curve(np.equal(y_hat, y_test),y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11c0bea90>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFkCAYAAACuFXjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+ETIDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11759c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc(fpr,tpr)\n",
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " acc = mt.accuracy_score(y_test,y_hat)\n",
    "            #         lr_clf_accuracies.append(acc)\n",
    "            #         cost_accuracies.append([acc])\n",
    "\n",
    "conf = mt.confusion_matrix(y_test,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = get_confusion_costTot(conf, cost_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "vals = {'n_hidden':150, \n",
    "         'C':0.002, 'epochs':75, 'eta':0.001, \n",
    "         'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "         'shuffle':True,'random_state':1, \n",
    "           'nonlinearity': \"sigmoid\"}\n",
    "custom_performances = []\n",
    "custom_times = []\n",
    "custom_mem = []\n",
    "sk_performances = []\n",
    "sk_times = []\n",
    "sk_mem = []\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "            \n",
    "            # I will create new variables here so that it is more obvious what \n",
    "            # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "            # but it makes this code less readable)\n",
    "            X_train = (X[train_indices])\n",
    "            y_train = y[train_indices]\n",
    "\n",
    "            X_test = (X[test_indices])\n",
    "            y_test = y[test_indices]\n",
    "\n",
    " \n",
    "            clf = MLPClassifier(hidden_layer_sizes=(50, ), \n",
    "                        activation='relu', # type of non-linearity, every layer\n",
    "                        solver='sgd', \n",
    "                        alpha=1e-4, # L2 penalty\n",
    "                        batch_size= 'auto', # min of 200, num_samples\n",
    "                        learning_rate='constant', # adapt learning? only for sgd\n",
    "                        learning_rate_init=0.1, # only SGD\n",
    "                        power_t=0.0,    # only SGD with inverse scaling of learning rate\n",
    "                        max_iter=75, # stopping criteria\n",
    "                        shuffle=True, \n",
    "                        random_state=1, \n",
    "                        tol=0, # for stopping\n",
    "                        verbose=False, \n",
    "                        warm_start=False, \n",
    "                        momentum=0.9, # only SGD\n",
    "                        nesterovs_momentum=False, # only SGD\n",
    "                        early_stopping=False, \n",
    "                        validation_fraction=0.0, # only if early_stop is true\n",
    "                        beta_1=0.9, # adam decay rate of moment\n",
    "                        beta_2=0.999, # adam decay rate of moment\n",
    "                        epsilon=1e-08) # adam numerical stabilizer\n",
    "            \n",
    "            print(\"SCIKIT*****\")\n",
    "            \n",
    "            st = time.time()\n",
    "\n",
    "            mem = memory_usage((clf.fit,(X_train,y_train))) # train object\n",
    "            t = (time.time() -st)\n",
    "            sk_times.append(t)\n",
    "            sk_mem.append(mem[0])\n",
    "#             %time clf.fit(X_train,y_train)\n",
    "            yhat2 = clf.predict(X_test)\n",
    "            print('Validation Acc:',accuracy_score(yhat2,y_test))\n",
    "            conf2 = mt.confusion_matrix(y_test,yhat2)\n",
    "                    #             print(vals)\n",
    "            #                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "            #                     plt.show()\n",
    "            print(\"confusion matrix\\n\",conf2)\n",
    "            score = get_confusion_costTot(conf2, cost_matrix)\n",
    "            print(\"Weighted Confusion Matrix Score: \", score)\n",
    "            sk_performances.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_fpr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-42d55a4e6af9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                                      \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                      pos_label=j)\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mperclass_mean_tpr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minterp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_fpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mperclass_mean_tpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_fpr' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "perclass_mean_tpr = 0.0\n",
    "roc_auc = 0\n",
    "classes = np.unique(y[train_indices])\n",
    "    # get the mean fpr and tpr, per class\n",
    "for j in classes:\n",
    "    fpr, tpr, thresholds = roc_curve(y[test_indices],\n",
    "                                     y_hat,\n",
    "                                     pos_label=j)\n",
    "    perclass_mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    perclass_mean_tpr[0] = 0.0\n",
    "    roc_auc += auc(fpr, tpr)\n",
    "\n",
    "perclass_mean_tpr /= len(classes)\n",
    "roc_auc /= len(classes)\n",
    "mean_tpr += perclass_mean_tpr\n",
    "plt.plot(mean_fpr,perclass_mean_tpr,'--',lw=1,label='Mean Class ROC fold %d (area = %0.2f)'\n",
    "               % (i+1, roc_auc))\n",
    "mean_tpr /= K\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr,perclass_mean_tpr,'k-',lw=2,label='Total Mean ROC (area = %0.2f)'\n",
    "                   % (mean_auc))\n",
    "plt.legend(loc='best')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Great! Its seems we are also maxing out the F1 score, lets go with C==1e-3\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "sklearn_version\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "K = 4\n",
    "\n",
    "if sklearn_version < '0.18':\n",
    "    from sklearn.cross_validation import StratifiedKFold\n",
    "    kfold = StratifiedKFold(y=y_train, \n",
    "                            n_folds=K,\n",
    "                            random_state=1)\n",
    "else:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kfold = StratifiedKFold(n_splits=K,\n",
    "                            random_state=1).split(X_train, y_train)\n",
    "\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "\n",
    "for i, (train, test) in enumerate(kfold):\n",
    "    probas = pipe_lr.fit(X_train[train],\n",
    "                         y_train[train]).predict_proba(X_train[test])\n",
    "\n",
    "    perclass_mean_tpr = 0.0\n",
    "    roc_auc = 0\n",
    "    classes = np.unique(y_train[train])\n",
    "    # get the mean fpr and tpr, per class\n",
    "    for j in classes:\n",
    "        fpr, tpr, thresholds = roc_curve(y_train[test],\n",
    "                                         probas[:, j],\n",
    "                                         pos_label=j)\n",
    "        perclass_mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        perclass_mean_tpr[0] = 0.0\n",
    "        roc_auc += auc(fpr, tpr)\n",
    "        \n",
    "    perclass_mean_tpr /= len(classes)\n",
    "    roc_auc /= len(classes)\n",
    "    mean_tpr += perclass_mean_tpr\n",
    "    plt.plot(mean_fpr,perclass_mean_tpr,'--',lw=1,label='Mean Class ROC fold %d (area = %0.2f)'\n",
    "                   % (i+1, roc_auc))\n",
    "    \n",
    "mean_tpr /= K\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr,perclass_mean_tpr,'k-',lw=2,label='Total Mean ROC (area = %0.2f)'\n",
    "                   % (mean_auc))\n",
    "plt.legend(loc='best')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
