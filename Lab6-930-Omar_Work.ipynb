{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "%load_ext memory_profiler\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.special import expit\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from memory_profiler import memory_usage\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "target_classifier = 'PC'\n",
    "df = pd.read_csv('responses.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove rows whose target classfier value is NaN\n",
    "df_cleaned_classifier = df[np.isfinite(df[target_classifier])]\n",
    "# change NaN number values to the mean\n",
    "df_imputed = df_cleaned_classifier.fillna(df.mean())\n",
    "# get categorical features\n",
    "object_features = list(df_cleaned_classifier.select_dtypes(include=['object']).columns)\n",
    "# one hot encode categorical features\n",
    "one_hot_df = pd.concat([pd.get_dummies(df_imputed[col],prefix=col) for col in object_features], axis=1)\n",
    "# drop object features from imputed dataframe\n",
    "df_imputed_dropped = df_imputed.drop(object_features, 1)\n",
    "frames = [df_imputed_dropped, one_hot_df]\n",
    "# concatenate both frames by columns\n",
    "df_fixed = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(get_confusion_costTot, greater_is_better=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Research on Cost Matrix\n",
    "# http://www.ibm.com/support/knowledgecenter/SSEPGG_11.1.0/com.ibm.im.model.doc/c_cost_matrix.html\n",
    "\n",
    "cost_matrix = np.matrix([[0,1,2,3,4],\n",
    "[1,0,1,2,3],\n",
    "[3,1,0,1,2],\n",
    "[5,3,1,0,1],\n",
    "[7,5,2,1,0]])\n",
    "\n",
    "def get_confusion_costTot(confusion_matrix, cost_matrix):\n",
    "    score = np.sum(confusion_matrix*cost_matrix)\n",
    "    return score\n",
    "\n",
    "confusion_scorer = make_scorer(get_confusion_costTot, greater_is_better=False)\n",
    "confusion_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if target_classifier in df_fixed:\n",
    "    y = df_fixed[target_classifier].values # get the labels we want\n",
    "    del df_fixed[target_classifier] # get rid of the class label\n",
    "    X = df_fixed.values # use everything else to predict!\n",
    "\n",
    "X = X/5\n",
    "num_folds = 10\n",
    "\n",
    "cv_object = StratifiedKFold(n_splits= num_folds, random_state=None, shuffle=True)\n",
    "cv_object.split(X,y)\n",
    "\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "        # I will create new variables here so that it is more obvious what \n",
    "        # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "        # but it makes this code less readable)\n",
    "        X_train = (X[train_indices])\n",
    "        y_train = y[train_indices]\n",
    "\n",
    "    #     print(X_train)\n",
    "    #     print(y_train)\n",
    "\n",
    "        X_test = (X[test_indices])\n",
    "        y_test = y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-713e26e72e50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# get the mean fpr and tpr, per class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     fpr, tpr, thresholds = roc_curve(y[test_indices],\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     pos_label=j)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "perclass_mean_tpr = 0.0\n",
    "roc_auc = 0\n",
    "classes = np.unique(y[train_indices])\n",
    "# get the mean fpr and tpr, per class\n",
    "for j in classes:\n",
    "    fpr, tpr, thresholds = roc_curve(y[test_indices],\n",
    "    y_hat,\n",
    "    pos_label=j)\n",
    "    perclass_mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    perclass_mean_tpr[0] = 0.0\n",
    "    roc_auc += auc(fpr, tpr)\n",
    "\n",
    "perclass_mean_tpr /= len(classes)\n",
    "roc_auc /= len(classes)\n",
    "mean_tpr += perclass_mean_tpr\n",
    "plt.plot(mean_fpr,perclass_mean_tpr,'--',lw=1,label='Mean Class ROC fold %d (area = %0.2f)'\n",
    "% (i+1, roc_auc))\n",
    "mean_tpr /= K\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr,perclass_mean_tpr,'k-',lw=2,label='Total Mean ROC (area = %0.2f)'\n",
    "% (mean_auc))\n",
    "plt.legend(loc='best')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "clf = MLPClassifier()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "class MyEnsemble():\n",
    "    \n",
    "    def __init__(self, c, num_c, max_s, v):\n",
    "        self.Ensemble = BaggingClassifier(base_estimator= c,\n",
    "                                    n_estimators = num_c,\n",
    "                                     max_samples = max_s,\n",
    "                                     verbose = v)\n",
    "    def predict(self, X):\n",
    "        return self.Ensemble.predict(X)\n",
    "    \n",
    "    def fit(self, X,y):\n",
    "        self.Ensemble.fit(X,y)\n",
    "        \n",
    "    def fit_random():\n",
    "        \n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        return self.Ensemble.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  8  2  1  0]\n",
      " [ 6  7  8  3  0]\n",
      " [ 3  2  7  4  4]\n",
      " [ 2  1  6  4  5]\n",
      " [ 1  2  2  8 11]]\n",
      "(906, 172)\n"
     ]
    }
   ],
   "source": [
    "num_instances = 10\n",
    "\n",
    "\n",
    "ensemble = MyEnsemble(clf, 10,y_train.shape[0],False)\n",
    "\n",
    "ensemble.fit(X_train,y_train)\n",
    "y_hat=ensemble.predict(X_test)\n",
    "# print(y_hat)\n",
    "print(mt.confusion_matrix(y_hat,y_test))\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.13567473e-02,   7.80820377e-02,   1.49648584e-01,\n",
       "          4.98719836e-01,   2.52192795e-01],\n",
       "       [  1.68573261e-01,   3.30600520e-01,   2.53932192e-01,\n",
       "          2.05113294e-01,   4.17807332e-02],\n",
       "       [  3.04691360e-03,   3.26662785e-02,   5.61833446e-02,\n",
       "          7.80429620e-01,   1.27673843e-01],\n",
       "       [  2.43917055e-01,   3.12643492e-01,   2.49683435e-01,\n",
       "          1.18149003e-01,   7.56070152e-02],\n",
       "       [  4.35595902e-01,   2.50006305e-01,   2.69534934e-01,\n",
       "          3.32737036e-02,   1.15891557e-02],\n",
       "       [  9.45286122e-02,   1.08462859e-01,   2.64324665e-01,\n",
       "          4.64878874e-01,   6.78049901e-02],\n",
       "       [  3.05854270e-03,   2.42194277e-02,   6.81727207e-02,\n",
       "          1.62198504e-01,   7.42350805e-01],\n",
       "       [  1.37649823e-01,   4.84684934e-01,   1.39503748e-01,\n",
       "          5.38579228e-02,   1.84303572e-01],\n",
       "       [  4.60385181e-02,   1.75355470e-01,   3.04740852e-01,\n",
       "          3.65799782e-01,   1.08065378e-01],\n",
       "       [  4.23592494e-02,   1.40781716e-01,   2.60131796e-01,\n",
       "          2.98863627e-01,   2.57863612e-01],\n",
       "       [  2.89114665e-01,   4.15717124e-01,   1.39175176e-01,\n",
       "          6.20248156e-02,   9.39682196e-02],\n",
       "       [  3.88984310e-01,   4.73283644e-01,   1.12186409e-01,\n",
       "          2.06078649e-02,   4.93777178e-03],\n",
       "       [  1.86357845e-01,   5.88679621e-01,   1.59444133e-01,\n",
       "          3.83989359e-02,   2.71194650e-02],\n",
       "       [  1.57651581e-01,   3.51357589e-01,   1.58217929e-01,\n",
       "          3.05401817e-01,   2.73710844e-02],\n",
       "       [  6.32218548e-02,   9.97207401e-02,   1.62966053e-01,\n",
       "          4.94069723e-01,   1.80021629e-01],\n",
       "       [  1.48258520e-01,   4.49149147e-01,   1.70819325e-01,\n",
       "          1.67150821e-01,   6.46221872e-02],\n",
       "       [  1.18554407e-01,   2.65539939e-01,   3.07002163e-01,\n",
       "          1.03961300e-01,   2.04942192e-01],\n",
       "       [  8.55204294e-02,   1.76367887e-01,   2.25107219e-01,\n",
       "          4.72174110e-01,   4.08303545e-02],\n",
       "       [  2.75473103e-01,   2.31992206e-01,   3.04511355e-01,\n",
       "          7.74080264e-02,   1.10615310e-01],\n",
       "       [  2.08816779e-02,   9.79806884e-02,   2.00673007e-01,\n",
       "          3.61734270e-01,   3.18730357e-01],\n",
       "       [  2.03698456e-01,   4.81266920e-01,   1.79333171e-01,\n",
       "          1.14232681e-01,   2.14687717e-02],\n",
       "       [  1.20070189e-01,   4.69323337e-01,   1.74692473e-01,\n",
       "          1.51037121e-01,   8.48768795e-02],\n",
       "       [  5.67101650e-03,   1.65187972e-02,   7.27559415e-02,\n",
       "          2.64352116e-01,   6.40702129e-01],\n",
       "       [  3.94610922e-02,   5.19244025e-02,   2.06979448e-01,\n",
       "          2.95192063e-01,   4.06442995e-01],\n",
       "       [  4.65636241e-01,   3.20960804e-01,   1.60309940e-01,\n",
       "          4.50436416e-02,   8.04937370e-03],\n",
       "       [  1.51714654e-02,   2.99551557e-01,   8.16424111e-02,\n",
       "          1.67625483e-01,   4.36009084e-01],\n",
       "       [  9.60395049e-03,   3.27831793e-02,   2.68622450e-01,\n",
       "          4.39864058e-01,   2.49126362e-01],\n",
       "       [  3.31094920e-02,   1.45360808e-01,   1.79198194e-01,\n",
       "          5.74830136e-01,   6.75013699e-02],\n",
       "       [  1.89500749e-01,   5.43106536e-01,   1.68937573e-01,\n",
       "          8.45049836e-02,   1.39501574e-02],\n",
       "       [  7.82817365e-02,   3.02862987e-01,   4.95735037e-01,\n",
       "          6.94410893e-02,   5.36791496e-02],\n",
       "       [  1.50552175e-01,   2.27202194e-01,   1.25470260e-01,\n",
       "          2.41931446e-01,   2.54843925e-01],\n",
       "       [  9.42590043e-02,   5.10920277e-01,   1.54598439e-01,\n",
       "          1.62008936e-01,   7.82133433e-02],\n",
       "       [  2.76532043e-01,   4.88299365e-01,   1.67577474e-01,\n",
       "          6.05801870e-02,   7.01093093e-03],\n",
       "       [  4.84258566e-01,   3.65299654e-01,   1.22859833e-01,\n",
       "          2.51202542e-02,   2.46169275e-03],\n",
       "       [  2.81577205e-01,   2.79049653e-01,   2.01408634e-01,\n",
       "          2.17735315e-01,   2.02291931e-02],\n",
       "       [  3.06994650e-01,   1.95859862e-01,   1.96615052e-01,\n",
       "          2.82455430e-01,   1.80750065e-02],\n",
       "       [  2.27250216e-03,   2.20716777e-02,   2.54955618e-01,\n",
       "          1.00617474e-01,   6.20082728e-01],\n",
       "       [  3.80075070e-02,   3.68332996e-01,   1.13043102e-01,\n",
       "          2.86423265e-01,   1.94193130e-01],\n",
       "       [  5.36575602e-02,   1.02077264e-01,   1.08397528e-01,\n",
       "          3.52922133e-01,   3.82945515e-01],\n",
       "       [  9.79404683e-02,   6.92206744e-02,   1.29661880e-01,\n",
       "          3.96131441e-01,   3.07045536e-01],\n",
       "       [  1.87558784e-01,   2.02832131e-01,   2.61069417e-01,\n",
       "          2.38150624e-01,   1.10389044e-01],\n",
       "       [  5.98261916e-02,   3.38502243e-01,   1.08312958e-01,\n",
       "          3.33816370e-01,   1.59542238e-01],\n",
       "       [  3.26487671e-02,   9.13703835e-02,   4.03358201e-01,\n",
       "          2.87952576e-01,   1.84670073e-01],\n",
       "       [  3.33731052e-01,   4.92032059e-01,   1.45381302e-01,\n",
       "          2.17892155e-02,   7.06637104e-03],\n",
       "       [  2.97847981e-03,   2.43754101e-02,   4.34965501e-02,\n",
       "          2.27921085e-01,   7.01228475e-01],\n",
       "       [  2.59379601e-01,   3.62699448e-01,   2.27361406e-01,\n",
       "          1.14149111e-01,   3.64104341e-02],\n",
       "       [  2.19545118e-02,   1.11558718e-01,   3.77500333e-01,\n",
       "          2.80559639e-01,   2.08426799e-01],\n",
       "       [  5.91815452e-01,   2.22827636e-01,   1.43570827e-01,\n",
       "          3.60312831e-02,   5.75480198e-03],\n",
       "       [  3.36227716e-01,   2.64909160e-01,   2.55823919e-01,\n",
       "          1.23023190e-01,   2.00160148e-02],\n",
       "       [  3.99833175e-02,   3.30793844e-02,   3.62637038e-01,\n",
       "          2.53972611e-01,   3.10327649e-01],\n",
       "       [  1.37087657e-02,   8.39826399e-02,   3.35219790e-02,\n",
       "          2.66423331e-01,   6.02363284e-01],\n",
       "       [  1.72502535e-01,   2.50179339e-01,   1.45144777e-01,\n",
       "          1.49079314e-01,   2.83094035e-01],\n",
       "       [  3.72374872e-01,   2.76298881e-01,   2.78484034e-01,\n",
       "          5.09258057e-02,   2.19164068e-02],\n",
       "       [  9.68542741e-03,   2.74607392e-02,   1.78575779e-01,\n",
       "          1.75204486e-01,   6.09073568e-01],\n",
       "       [  9.92673005e-02,   1.83318677e-01,   4.86136917e-01,\n",
       "          1.59417445e-01,   7.18596597e-02],\n",
       "       [  2.17744375e-01,   2.80389818e-01,   1.25421079e-01,\n",
       "          3.42296389e-01,   3.41483393e-02],\n",
       "       [  4.57145534e-03,   1.62337676e-02,   1.50994185e-01,\n",
       "          3.02923444e-01,   5.25277148e-01],\n",
       "       [  9.03000884e-02,   1.47127192e-01,   4.74532304e-01,\n",
       "          1.89204717e-01,   9.88356989e-02],\n",
       "       [  1.74086500e-01,   2.89507181e-01,   3.19292083e-01,\n",
       "          1.56065338e-01,   6.10488969e-02],\n",
       "       [  1.46037053e-02,   9.55851670e-02,   1.20677669e-01,\n",
       "          1.71779473e-01,   5.97353986e-01],\n",
       "       [  4.52813789e-01,   3.99946421e-01,   9.54033322e-02,\n",
       "          4.83262862e-02,   3.51017231e-03],\n",
       "       [  1.06987075e-02,   3.53107204e-02,   2.87858696e-01,\n",
       "          1.70962389e-01,   4.95169487e-01],\n",
       "       [  1.01568903e-01,   2.51624988e-01,   3.09777192e-01,\n",
       "          1.72041530e-01,   1.64987387e-01],\n",
       "       [  3.16406711e-01,   3.50593919e-01,   2.58868734e-01,\n",
       "          5.82425065e-02,   1.58881295e-02],\n",
       "       [  3.14681104e-01,   2.09640996e-01,   1.89955663e-01,\n",
       "          2.13624201e-01,   7.20980363e-02],\n",
       "       [  2.93642860e-01,   2.96741111e-01,   2.20021469e-01,\n",
       "          8.10445531e-02,   1.08550007e-01],\n",
       "       [  3.58529601e-02,   1.37910295e-01,   2.57490956e-01,\n",
       "          4.54313496e-01,   1.14432293e-01],\n",
       "       [  2.49758852e-02,   1.93412584e-01,   1.50848508e-01,\n",
       "          3.11358686e-01,   3.19404338e-01],\n",
       "       [  2.26577984e-02,   9.88992591e-02,   3.01045636e-01,\n",
       "          3.67695635e-01,   2.09701672e-01],\n",
       "       [  1.86302548e-01,   4.45265586e-01,   2.98774395e-01,\n",
       "          6.09654589e-02,   8.69201271e-03],\n",
       "       [  8.36391608e-02,   5.06985516e-01,   2.83133681e-01,\n",
       "          7.68328815e-02,   4.94087609e-02],\n",
       "       [  1.43662905e-01,   2.01023702e-01,   2.09706720e-01,\n",
       "          2.16502129e-01,   2.29104544e-01],\n",
       "       [  7.74113805e-03,   1.93751121e-02,   6.65564934e-02,\n",
       "          4.52391345e-01,   4.53935912e-01],\n",
       "       [  1.07021851e-01,   6.70779841e-01,   1.53436630e-01,\n",
       "          4.36052977e-02,   2.51563806e-02],\n",
       "       [  1.15866251e-01,   1.10167897e-01,   3.50135072e-01,\n",
       "          2.66810558e-01,   1.57020222e-01],\n",
       "       [  6.85895948e-02,   6.38482518e-02,   1.36809843e-01,\n",
       "          3.25991282e-01,   4.04761028e-01],\n",
       "       [  4.39425276e-02,   7.47530899e-02,   1.65961077e-01,\n",
       "          2.37008591e-01,   4.78334714e-01],\n",
       "       [  4.35206316e-02,   1.20524459e-01,   3.95334865e-01,\n",
       "          3.85646167e-01,   5.49738768e-02],\n",
       "       [  1.73230209e-01,   1.95616670e-01,   4.42040079e-01,\n",
       "          1.50322585e-01,   3.87904572e-02],\n",
       "       [  3.16908792e-02,   9.90960583e-02,   3.11198075e-01,\n",
       "          3.78685021e-01,   1.79329966e-01],\n",
       "       [  6.04516984e-01,   1.26339984e-01,   2.42298934e-01,\n",
       "          2.57061197e-02,   1.13797794e-03],\n",
       "       [  3.17161120e-02,   7.31907009e-02,   2.03507568e-01,\n",
       "          1.69164649e-01,   5.22420969e-01],\n",
       "       [  1.49358224e-02,   9.18708929e-02,   3.36707698e-01,\n",
       "          2.23941747e-01,   3.32543839e-01],\n",
       "       [  1.61389110e-02,   5.91783861e-02,   4.00065695e-01,\n",
       "          3.76103739e-01,   1.48513269e-01],\n",
       "       [  7.27914538e-03,   5.72168455e-02,   1.63372419e-01,\n",
       "          2.84818116e-01,   4.87313474e-01],\n",
       "       [  4.14380831e-02,   1.66053366e-01,   1.75795492e-01,\n",
       "          5.25223353e-01,   9.14897053e-02],\n",
       "       [  6.09108565e-03,   1.97059336e-02,   5.86454900e-02,\n",
       "          4.87609989e-01,   4.27947502e-01],\n",
       "       [  3.60154329e-02,   1.00177831e-01,   2.31638119e-01,\n",
       "          3.10256405e-01,   3.21912212e-01],\n",
       "       [  2.53963430e-01,   3.34166098e-01,   3.04153930e-01,\n",
       "          9.37076550e-02,   1.40088868e-02],\n",
       "       [  7.61603098e-04,   7.87635926e-03,   3.20687703e-02,\n",
       "          1.19508998e-01,   8.39784270e-01],\n",
       "       [  1.07156878e-01,   2.02703787e-01,   4.32852296e-01,\n",
       "          1.93919919e-01,   6.33671195e-02],\n",
       "       [  2.07635373e-02,   9.15786943e-02,   1.07149237e-01,\n",
       "          4.71060656e-01,   3.09447875e-01],\n",
       "       [  4.37586880e-01,   1.63442383e-01,   1.78238298e-01,\n",
       "          2.04237366e-01,   1.64950732e-02],\n",
       "       [  1.70995953e-01,   1.84156841e-01,   4.40692894e-01,\n",
       "          1.86539865e-01,   1.76144468e-02],\n",
       "       [  2.04620966e-02,   3.98786632e-01,   2.47459682e-01,\n",
       "          2.30422272e-01,   1.02869317e-01],\n",
       "       [  8.49832460e-02,   1.60196425e-01,   3.91704875e-01,\n",
       "          2.97907421e-01,   6.52080338e-02],\n",
       "       [  2.21351041e-02,   8.98613953e-02,   3.14078399e-01,\n",
       "          2.39163694e-01,   3.34761408e-01],\n",
       "       [  2.19497636e-01,   2.85175536e-01,   2.89804531e-01,\n",
       "          1.70164898e-01,   3.53573999e-02]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  6  3  2  1]\n",
      " [ 8  7  2  1  2]\n",
      " [ 2  8  7  6  2]\n",
      " [ 1  3  4  4  8]\n",
      " [ 0  0  4  5 11]]\n"
     ]
    }
   ],
   "source": [
    " acc = mt.accuracy_score(y_test,y_hat)\n",
    "            #         lr_clf_accuracies.append(acc)\n",
    "            #         cost_accuracies.append([acc])\n",
    "\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-2f506efacab3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-2f506efacab3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    confidence = ensemble.\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "confidence = ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = get_confusion_costTot(conf, cost_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Great! Its seems we are also maxing out the F1 score, lets go with C==1e-3\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "K = 4\n",
    "\n",
    "if sklearn_version < '0.18':\n",
    "    from sklearn.cross_validation import StratifiedKFold\n",
    "    kfold = StratifiedKFold(y=y_train, \n",
    "                            n_folds=K,\n",
    "                            random_state=1)\n",
    "else:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kfold = StratifiedKFold(n_splits=K,\n",
    "                            random_state=1).split(X_train, y_train)\n",
    "\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "\n",
    "for i, (train, test) in enumerate(kfold):\n",
    "    probas = pipe_lr.fit(X_train[train],\n",
    "                         y_train[train]).predict_proba(X_train[test])\n",
    "\n",
    "    perclass_mean_tpr = 0.0\n",
    "    roc_auc = 0\n",
    "    classes = np.unique(y_train[train])\n",
    "    # get the mean fpr and tpr, per class\n",
    "    for j in classes:\n",
    "        fpr, tpr, thresholds = roc_curve(y_train[test],\n",
    "                                         probas[:, j],\n",
    "                                         pos_label=j)\n",
    "        perclass_mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        perclass_mean_tpr[0] = 0.0\n",
    "        roc_auc += auc(fpr, tpr)\n",
    "        \n",
    "    perclass_mean_tpr /= len(classes)\n",
    "    roc_auc /= len(classes)\n",
    "    mean_tpr += perclass_mean_tpr\n",
    "    plt.plot(mean_fpr,perclass_mean_tpr,'--',lw=1,label='Mean Class ROC fold %d (area = %0.2f)'\n",
    "                   % (i+1, roc_auc))\n",
    "    \n",
    "mean_tpr /= K\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr,perclass_mean_tpr,'k-',lw=2,label='Total Mean ROC (area = %0.2f)'\n",
    "                   % (mean_auc))\n",
    "plt.legend(loc='best')\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
