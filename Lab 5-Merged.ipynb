{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Five: Evaluation and Multi-Layer Perceptron\n",
    "## Rupal Sanghavi, Omar Roa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset represents the responses from students and their friends(ages 15-30, henceforth stated as \"young people\") of a Statistics class from the Faculty of Social and Economic Sciences at The Comenius University in Bratislava, Slovakia. Their survey was a mix of various topics.\n",
    "\n",
    "* Music preferences (19 items)\n",
    "* Movie preferences (12 items)\n",
    "* Hobbies & interests (32 items)\n",
    "* Phobias (10 items)\n",
    "* Health habits (3 items)\n",
    "* Personality traits, views on life, & opinions (57 items)\n",
    "* Spending habits (7 items)\n",
    "* Demographics (10 items)\n",
    "\n",
    "The dataset can be found here. https://www.kaggle.com/miroslavsabo/young-people-survey\n",
    "\n",
    "Our target is to predict how likely a young person would have an interest in PC Software and Hardware. According to Time Magazine (http://time.com/4433964/teens-social-media-advertising/), \"YouTube has become so saturated with popular vloggers that marketers are now turning to so-called \"micro-influencers\" with smaller but more devoted followings, while agencies are shifting their ad dollars from television to YouTube.\"\n",
    "\n",
    "What is a \"micro-influencer\"? \"A micro-influencer is usually Instafamous or a Youtube sensation with a relatively high social following who they have a great impact on.\" (https://www.bcsagency.com/news/step-aside-bloggers-its-time-for-micro-influencers-to-take-the-stage) According to Digiday (http://digiday.com/marketing/micro-influencers/), if a content creator with a large audience promotes a product, there is a chance that only a small subset of their audience is interested. A \"micro-influencer\" would likely have an audience that we mostly interested in a product placement by their trusted \"micro-influencer\".\n",
    "\n",
    "PC Software and Hardware is the classifier that we chose for this project, but there are various other interests in our dataset (Socializing, Dancing, Art) that could be predicted. The point is to gauge interest in a particular topic, hire a \"micro-influencer\" to generate content for that topic, and include product placement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "%load_ext memory_profiler\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.special import expit\n",
    "import time\n",
    "import math\n",
    "from memory_profiler import memory_usage\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "target_classifier = 'PC'\n",
    "df = pd.read_csv('responses.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove rows whose target classfier value is NaN\n",
    "df_cleaned_classifier = df[np.isfinite(df[target_classifier])]\n",
    "# change NaN number values to the mean\n",
    "df_imputed = df_cleaned_classifier.fillna(df.mean())\n",
    "# get categorical features\n",
    "object_features = list(df_cleaned_classifier.select_dtypes(include=['object']).columns)\n",
    "# one hot encode categorical features\n",
    "one_hot_df = pd.concat([pd.get_dummies(df_imputed[col],prefix=col) for col in object_features], axis=1)\n",
    "# drop object features from imputed dataframe\n",
    "df_imputed_dropped = df_imputed.drop(object_features, 1)\n",
    "frames = [df_imputed_dropped, one_hot_df]\n",
    "# concatenate both frames by columns\n",
    "df_fixed = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_classifier.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1004, 173)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fixed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset (1010 rows and 150 columns) was mostly ordinal data as numbers (preferences ranked 1-5) . We also had some ordinal data as strings. \n",
    "\n",
    "e.g.\n",
    "How much time do you spend online?: No time at all - Less than an hour a day - Few hours a day - Most of the day\n",
    "\n",
    "We first removed any rows which contained NaN values for our target classifer, Shopping centres. Afterwards we imputed mean values for any NaN values in other features. We decided to impute due to the fact that there were not many NaN values in our features compared to the size of our data set. (At most was 20 for a feature, as shown above). We then one-hot encoded any string object, which created extra features.\n",
    "\n",
    "We are left with numerical values for our features and a size of 1007 x 172"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics To Evaluate Algorithm's Generalization Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(get_confusion_costTot, greater_is_better=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Research on Cost Matrix\n",
    "# http://www.ibm.com/support/knowledgecenter/SSEPGG_11.1.0/com.ibm.im.model.doc/c_cost_matrix.html\n",
    "\n",
    "cost_matrix = np.matrix([[0,1,2,3,4],\n",
    "[1,0,1,2,3],\n",
    "[3,1,0,1,2],\n",
    "[5,3,1,0,1],\n",
    "[7,5,2,1,0]])\n",
    "\n",
    "def get_confusion_costTot(confusion_matrix, cost_matrix):\n",
    "    score = np.sum(confusion_matrix*cost_matrix)\n",
    "    return score\n",
    "\n",
    "confusion_scorer = make_scorer(get_confusion_costTot, greater_is_better=False)\n",
    "confusion_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if target_classifier in df_fixed:\n",
    "    y = df_fixed[target_classifier].values # get the label we want\n",
    "    del df_fixed[target_classifier] # get rid of the class label\n",
    "    X = df_fixed.values # use everything else to predict!\n",
    "\n",
    "X = X/5\n",
    "num_folds = 10\n",
    "\n",
    "cv_object = StratifiedKFold(n_splits= num_folds, random_state=None, shuffle=True)\n",
    "cv_object.split(X,y)\n",
    "\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using Stratified K Fold as our cross-validation object. Scikit's page states \"each set contains approximately the same percentage of samples of each target class as the complete set.\"(http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) This is important as we want to represent the dataset as accurately as possible. Kfolds also includes all our data over the course of the folds, so we know that all our data is being used at some point.\n",
    "\n",
    "We did not split our data into validation/train/test sets due to the fact that our data sample size is small (just over 1000 samples). We kept our data set split into training and test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Implementation of Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example adapted from https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "# Original Author: Sebastian Raschka\n",
    "# This is the optional book we use in the course, excellent intuitions and straightforward programming examples\n",
    "# please note, however, that this code has been manipulated to reflect our assumptions and notation.\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# start with a simple base classifier, which can't be fit or predicted\n",
    "# it only has internal classes to be used by classes that will subclass it\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None, nonlinearity = \"sigmoid\"):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.params = {}\n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "            \n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        W1_num_elems = (self.n_features_ + 1)*self.n_hidden\n",
    "        W1 = np.random.uniform(-1.0, 1.0,size=W1_num_elems)\n",
    "        W1 = W1.reshape(self.n_hidden, self.n_features_ + 1) # reshape to be W\n",
    "        \n",
    "        W2_num_elems = (self.n_hidden + 1)*self.n_output_\n",
    "        W2 = np.random.uniform(-1.0, 1.0, size=W2_num_elems)\n",
    "        W2 = W2.reshape(self.n_output_, self.n_hidden + 1)\n",
    "        return W1, W2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
    "        # 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_/2.0) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2))\n",
    "    \n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = np.mean((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _feedforward(self, X, W1, W2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        \"\"\"\n",
    "        A1 = self._add_bias_unit(X, how='column')\n",
    "        Z1 = W1 @ A1.T\n",
    "        if(self.nonlinearity == \"sigmoid\"):\n",
    "            A2 = self._sigmoid(Z1)\n",
    "            A2 = self._add_bias_unit(A2, how='row')\n",
    "            Z2 = W2 @ A2\n",
    "            A3 = self._sigmoid(Z2)\n",
    "        else:\n",
    "            A2 = Z1\n",
    "            A2 = self._add_bias_unit(A2, how='row')\n",
    "            Z2 = W2 @ A2\n",
    "            A3 = Z2\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        if(self.nonlinearity == \"sigmoid\"):\n",
    "            sigma3 = -2*(Y_enc-A3)*A3*(1-A3)\n",
    "            sigma2 = (W2.T @ sigma3)*A2*(1-A2)\n",
    "        else:\n",
    "            sigma3 = -2*(Y_enc-A3)\n",
    "            sigma2 = (W2.T @ sigma3)\n",
    "            \n",
    "        grad1 = sigma2[1:,:] @ A1\n",
    "        grad2 = sigma3 @ A2.T\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += W1[:, 1:] * self.l2_C\n",
    "        grad2[:, 1:] += W2[:, 1:] * self.l2_C\n",
    "\n",
    "        return grad1, grad2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred\n",
    "    def get_params(self,deep=False):\n",
    "        return dict(n_hidden=self.n_hidden, C=self.l2_C, nonlinearity=self.nonlinearity)\n",
    "\n",
    "    def set_params(self,**kwds):\n",
    "        print(kwds)\n",
    "        self.n_hidden = kwds['n_hidden']\n",
    "        self.C = kwds['C']\n",
    "        self.nonlinearity = kwds['nonlinearity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# just start with the vectorized version and minibatch\n",
    "class TLPMiniBatch(TwoLayerPerceptronBase):\n",
    "    def __init__(self, alpha=0.0, decrease_const=0.0, shuffle=True, \n",
    "                 minibatches=1, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        delta_W1_prev = np.zeros(self.W1.shape)\n",
    "        delta_W2_prev = np.zeros(self.W2.shape)\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            self.eta /= (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       self.W1,\n",
    "                                                       self.W2)\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],self.W1,self.W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, \n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=self.W1,W2=self.W2)\n",
    "\n",
    "                delta_W1, delta_W2 = self.eta * grad1, self.eta * grad2\n",
    "                self.W1 -= (delta_W1 + (self.alpha * delta_W1_prev))\n",
    "                self.W2 -= (delta_W2 + (self.alpha * delta_W2_prev))\n",
    "                delta_W1_prev, delta_W2_prev = delta_W1, delta_W2\n",
    "\n",
    "            self.cost_.append(mini_cost)\n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            \n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to implement the new style of objective function, \n",
    "# we just need to update the final layer calculation of the gradient\n",
    "class TLPMiniBatchCrossEntropy(TLPMiniBatch):\n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A3)+(1-Y_enc)*np.log(1-A3))))\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        sigma3 = (A3-Y_enc) # <- this is only line that changed\n",
    "        if(self.nonlinearity == \"sigmoid\"):\n",
    "            sigma2 = (W2.T @ sigma3)*A2*(1-A2)\n",
    "            grad1 = sigma2[1:,:] @ A1\n",
    "            grad2 = sigma3 @ A2.T\n",
    "        else:\n",
    "            sigma2 = (W2.T @ sigma3)\n",
    "            grad1 = sigma2[1:,:] @ A1\n",
    "            grad2 = sigma3\n",
    "        #grad1 = sigma2[1:,:] @ A1\n",
    "        #grad2 = sigma3 @ A2.T\n",
    "        grad2 = sigma3 @ A2.T\n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += W1[:, 1:] * self.l2_C\n",
    "        grad2[:, 1:] += W2[:, 1:] * self.l2_C\n",
    "\n",
    "        return grad1, grad2\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TLPDropoutQuad(TLPMiniBatch):\n",
    "    def __init__(self, dropout=True, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.dropout = dropout\n",
    "\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    def fit(self, X, y, print_progress=0, XY_test=None):\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        delta_W1_prev = np.zeros(self.W1.shape)\n",
    "        delta_W2_prev = np.zeros(self.W2.shape)\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        if XY_test is not None:\n",
    "            X_test = XY_test[0].copy()\n",
    "            y_test = XY_test[1].copy()\n",
    "            self.val_score_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            self.eta /= (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            \n",
    "            # adding dropout neurons\n",
    "            W1 = self.W1.copy()\n",
    "            W2 = self.W2.copy()\n",
    "            \n",
    "            if self.dropout:\n",
    "                # be sure to select the other half of the neurons each epoch\n",
    "                if True :#i%2 == 0:\n",
    "                    # randomly select half of the neurons\n",
    "                    idx_dropout = np.random.permutation(W1.shape[0])\n",
    "                    idx_other_half = idx_dropout[:int(W1.shape[0]/2)]\n",
    "                    idx_dropout = idx_dropout[int(W1.shape[0]/2):] #drop half\n",
    "                else:\n",
    "                    # select the other half\n",
    "                    idx_dropout = idx_other_half\n",
    "                    \n",
    "                idx_dropout = np.sort(idx_dropout)\n",
    "                idx_W2_withbias = np.hstack(([0],(idx_dropout+1)))\n",
    "                W1 = W1[idx_dropout,:]# get rid of rows\n",
    "                W2 = W2[:,idx_W2_withbias]# get rid of extra columns\n",
    "                delta_W1_prev_dropout = delta_W1_prev[idx_dropout,:]\n",
    "                delta_W2_prev_dropout = delta_W2_prev[:,idx_W2_withbias]\n",
    "            else:\n",
    "                delta_W1_prev_dropout = delta_W1_prev\n",
    "                delta_W2_prev_dropout = delta_W2_prev\n",
    "                \n",
    "            \n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       W1,\n",
    "                                                       W2)\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],W1,W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2,\n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=W1,W2=W2)\n",
    "\n",
    "                delta_W1, delta_W2 = self.eta * grad1, self.eta * grad2\n",
    "                W1 -= (delta_W1 + (self.alpha * delta_W1_prev_dropout))\n",
    "                W2 -= (delta_W2 + (self.alpha * delta_W2_prev_dropout))\n",
    "                delta_W1_prev_dropout, delta_W2_prev_dropout = delta_W1, delta_W2\n",
    "\n",
    "            if self.dropout:\n",
    "                # now append the learned weights back into the original matrices\n",
    "                self.W1[idx_dropout,:] = W1\n",
    "                self.W2[:,idx_W2_withbias] = W2\n",
    "                delta_W1_prev[idx_dropout,:] = delta_W1_prev_dropout\n",
    "                delta_W2_prev[:,idx_W2_withbias] = delta_W2_prev_dropout\n",
    "            else:\n",
    "                # don't eliminate any neurons\n",
    "                self.W1 = W1\n",
    "                self.W2 = W2\n",
    "                delta_W1_prev = delta_W1_prev_dropout\n",
    "                delta_W2_prev = delta_W2_prev_dropout\n",
    "                \n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            self.cost_.append(mini_cost) # only uses dropped samples, so more noise\n",
    "            if XY_test is not None:\n",
    "                self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class TLPDropout(TLPMiniBatchCrossEntropy):\n",
    "    def __init__(self, dropout=True, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.dropout = dropout\n",
    "\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    def fit(self, X, y, print_progress=0, XY_test=None):\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        delta_W1_prev = np.zeros(self.W1.shape)\n",
    "        delta_W2_prev = np.zeros(self.W2.shape)\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        if XY_test is not None:\n",
    "            X_test = XY_test[0].copy()\n",
    "            y_test = XY_test[1].copy()\n",
    "            self.val_score_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            self.eta /= (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            \n",
    "            # adding dropout neurons\n",
    "            W1 = self.W1.copy()\n",
    "            W2 = self.W2.copy()\n",
    "            \n",
    "            if self.dropout:\n",
    "                # be sure to select the other half of the neurons each epoch\n",
    "                if True :#i%2 == 0:\n",
    "                    # randomly select half of the neurons\n",
    "                    idx_dropout = np.random.permutation(W1.shape[0])\n",
    "                    idx_other_half = idx_dropout[:int(W1.shape[0]/2)]\n",
    "                    idx_dropout = idx_dropout[int(W1.shape[0]/2):] #drop half\n",
    "                else:\n",
    "                    # select the other half\n",
    "                    idx_dropout = idx_other_half\n",
    "                    \n",
    "                idx_dropout = np.sort(idx_dropout)\n",
    "                idx_W2_withbias = np.hstack(([0],(idx_dropout+1)))\n",
    "                W1 = W1[idx_dropout,:]# get rid of rows\n",
    "                W2 = W2[:,idx_W2_withbias]# get rid of extra columns\n",
    "                delta_W1_prev_dropout = delta_W1_prev[idx_dropout,:]\n",
    "                delta_W2_prev_dropout = delta_W2_prev[:,idx_W2_withbias]\n",
    "            else:\n",
    "                delta_W1_prev_dropout = delta_W1_prev\n",
    "                delta_W2_prev_dropout = delta_W2_prev\n",
    "                \n",
    "            \n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       W1,\n",
    "                                                       W2)\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],W1,W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2,\n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=W1,W2=W2)\n",
    "\n",
    "                delta_W1, delta_W2 = self.eta * grad1, self.eta * grad2\n",
    "                W1 -= (delta_W1 + (self.alpha * delta_W1_prev_dropout))\n",
    "                W2 -= (delta_W2 + (self.alpha * delta_W2_prev_dropout))\n",
    "                delta_W1_prev_dropout, delta_W2_prev_dropout = delta_W1, delta_W2\n",
    "\n",
    "            if self.dropout:\n",
    "                # now append the learned weights back into the original matrices\n",
    "                self.W1[idx_dropout,:] = W1\n",
    "                self.W2[:,idx_W2_withbias] = W2\n",
    "                delta_W1_prev[idx_dropout,:] = delta_W1_prev_dropout\n",
    "                delta_W2_prev[:,idx_W2_withbias] = delta_W2_prev_dropout\n",
    "            else:\n",
    "                # don't eliminate any neurons\n",
    "                self.W1 = W1\n",
    "                self.W2 = W2\n",
    "                delta_W1_prev = delta_W1_prev_dropout\n",
    "                delta_W2_prev = delta_W2_prev_dropout\n",
    "                \n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            self.cost_.append(mini_cost) # only uses dropped samples, so more noise\n",
    "            if XY_test is not None:\n",
    "                self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TLPGaussianInitialQuad(TLPMiniBatch):             \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with smal l random numbers.\"\"\"\n",
    "        W1 = np.random.randn(self.n_hidden, self.n_features_ + 1)\n",
    "        W1[:,1:] = W1[:,1:]/np.sqrt(self.n_features_+1) # don't saturate the neuron\n",
    "        \n",
    "        W2 = np.random.randn(self.n_output_, self.n_hidden + 1)\n",
    "        W2[:,1:] = W2[:,1:]/np.sqrt(self.n_hidden+1) # don't saturate the neuron\n",
    "        return W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TLPGaussianInitial(TLPMiniBatchCrossEntropy):             \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        W1 = np.random.randn(self.n_hidden, self.n_features_ + 1)\n",
    "        W1[:,1:] = W1[:,1:]/np.sqrt(self.n_features_+1) # don't saturate the neuron\n",
    "        \n",
    "        W2 = np.random.randn(self.n_output_, self.n_hidden + 1)\n",
    "        W2[:,1:] = W2[:,1:]/np.sqrt(self.n_hidden+1) # don't saturate the neuron\n",
    "        return W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals = {'n_hidden':50, \n",
    "         'C':1e-2, 'epochs':75, 'eta':0.001, \n",
    "         'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "         'shuffle':True,'random_state':1, 'dropout':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TLPReLu(TLPDropout):\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        # suggested relu/sigmoid bounds\n",
    "        # Glorot, Xavier, Antoine Bordes, and Yoshua Bengio. \n",
    "        #   \"Deep Sparse Rectifier Neural Networks.\"\n",
    "        init_bound = np.sqrt(6. / (self.n_hidden + self.n_features_ + 1))\n",
    "        W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_ + 1))\n",
    "\n",
    "        init_bound = np.sqrt(2. / (self.n_output_ + self.n_hidden + 1))\n",
    "        W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden + 1))\n",
    "        return W1, W2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _relu(Z):\n",
    "        return np.maximum(0,Z.copy())\n",
    "        \n",
    "    def _feedforward(self, X, W1, W2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        \"\"\"\n",
    "        # A1->W1->ReLu->A2->W2->Sigmoid\n",
    "        A1 = self._add_bias_unit(X, how='column')\n",
    "        Z1 = W1 @ A1.T\n",
    "        A2 = self._relu(Z1)\n",
    "        A2 = self._add_bias_unit(A2, how='row')\n",
    "        Z2 = W2 @ A2\n",
    "        A3 = self._sigmoid(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        sigma3 = (A3-Y_enc) \n",
    "        # sigma3[Z2<=0] = 0 # can change to be relu back prop on this layer too!\n",
    "        \n",
    "        sigma2 = (W2.T @ sigma3) \n",
    "        Z1_with_bias = self._add_bias_unit(Z1,how='row')\n",
    "        sigma2[Z1_with_bias<=0] = 0\n",
    "        # relu derivative only zeros out certain values! easy!\n",
    "        \n",
    "        grad1 = sigma2[1:,:] @ A1\n",
    "        grad2 = sigma3 @ A2.T\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += (W1[:, 1:] * self.l2_C)\n",
    "        grad2[:, 1:] += (W2[:, 1:] * self.l2_C)\n",
    "\n",
    "        return grad1, grad2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 344 ms, total: 14.8 s\n",
      "Wall time: 8.66 s\n",
      "confusion matrix\n",
      " [[ 0  9  1  0  4]\n",
      " [ 0 11  5  0  5]\n",
      " [ 0 11  8  0  6]\n",
      " [ 0 10  4  0  7]\n",
      " [ 0  1 10  0 10]]\n",
      "Weighted Confusion Matrix Score:  970\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 s, sys: 300 ms, total: 14.1 s\n",
      "Wall time: 7.81 s\n",
      "confusion matrix\n",
      " [[ 0  6  6  0  2]\n",
      " [ 0  7  8  0  6]\n",
      " [ 0  6  9  0 10]\n",
      " [ 0  7  7  0  7]\n",
      " [ 0  4  2  0 15]]\n",
      "Weighted Confusion Matrix Score:  1034\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 224 ms, total: 13.3 s\n",
      "Wall time: 6.87 s\n",
      "confusion matrix\n",
      " [[ 0  9  5  0  0]\n",
      " [ 0  6 13  0  2]\n",
      " [ 0  4 17  0  4]\n",
      " [ 0  1 13  0  7]\n",
      " [ 0  2  9  0 10]]\n",
      "Weighted Confusion Matrix Score:  898\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 s, sys: 327 ms, total: 14.5 s\n",
      "Wall time: 8.4 s\n",
      "confusion matrix\n",
      " [[ 0  6  8  0  0]\n",
      " [ 0  8 11  0  2]\n",
      " [ 0  6 14  0  5]\n",
      " [ 0  4 11  0  6]\n",
      " [ 0  1 13  0  7]]\n",
      "Weighted Confusion Matrix Score:  874\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 441 ms, total: 15.7 s\n",
      "Wall time: 9.88 s\n",
      "confusion matrix\n",
      " [[ 0  2 10  0  2]\n",
      " [ 0  2 17  0  2]\n",
      " [ 0  3 14  0  8]\n",
      " [ 0  4  9  0  8]\n",
      " [ 0  1  7  0 12]]\n",
      "Weighted Confusion Matrix Score:  963\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 248 ms, total: 13.7 s\n",
      "Wall time: 7.17 s\n",
      "confusion matrix\n",
      " [[ 0  4  6  1  2]\n",
      " [ 0  9  9  0  3]\n",
      " [ 0  7  9  0  9]\n",
      " [ 0  6  7  0  8]\n",
      " [ 0  1  6  0 13]]\n",
      "Weighted Confusion Matrix Score:  983\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 228 ms, total: 13.3 s\n",
      "Wall time: 6.86 s\n",
      "confusion matrix\n",
      " [[ 0 11  2  0  0]\n",
      " [ 0 16  3  0  2]\n",
      " [ 0 13  9  0  3]\n",
      " [ 0  9  6  0  6]\n",
      " [ 0  3 10  0  7]]\n",
      "Weighted Confusion Matrix Score:  844\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 s, sys: 212 ms, total: 13.2 s\n",
      "Wall time: 6.83 s\n",
      "confusion matrix\n",
      " [[ 0  6  6  0  1]\n",
      " [ 0  9  8  0  4]\n",
      " [ 0  5  9  0 11]\n",
      " [ 0  1  6  0 13]\n",
      " [ 0  1  6  0 13]]\n",
      "Weighted Confusion Matrix Score:  1029\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 s, sys: 222 ms, total: 13.2 s\n",
      "Wall time: 6.79 s\n",
      "confusion matrix\n",
      " [[ 0  5  6  0  2]\n",
      " [ 0  5 15  0  0]\n",
      " [ 0  4 17  0  4]\n",
      " [ 0  1 15  0  4]\n",
      " [ 0  1 12  0  7]]\n",
      "Weighted Confusion Matrix Score:  822\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 s, sys: 232 ms, total: 13.3 s\n",
      "Wall time: 6.81 s\n",
      "confusion matrix\n",
      " [[ 0  8  5  0  0]\n",
      " [ 0  7 12  0  1]\n",
      " [ 0  2 14  0  9]\n",
      " [ 0  3  9  0  8]\n",
      " [ 0  4  3  0 13]]\n",
      "Weighted Confusion Matrix Score:  934\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 s, sys: 295 ms, total: 12.9 s\n",
      "Wall time: 7.4 s\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [21  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1020\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 s, sys: 212 ms, total: 12.4 s\n",
      "Wall time: 6.38 s\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [21  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1020\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 210 ms, total: 12.3 s\n",
      "Wall time: 6.32 s\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [21  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1020\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 s, sys: 210 ms, total: 12.4 s\n",
      "Wall time: 6.37 s\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [21  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1020\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 230 ms, total: 12.6 s\n",
      "Wall time: 6.68 s\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [20  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1010\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 s, sys: 220 ms, total: 12.4 s\n",
      "Wall time: 6.4 s\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [20  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1000\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 203 ms, total: 12.3 s\n",
      "Wall time: 6.36 s\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [20  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1000\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 203 ms, total: 12.3 s\n",
      "Wall time: 6.32 s\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [20  0  0  0  0]\n",
      " [20  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  990\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 214 ms, total: 12.3 s\n",
      "Wall time: 6.34 s\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [20  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [20  0  0  0  0]\n",
      " [20  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  980\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 s, sys: 229 ms, total: 12.4 s\n",
      "Wall time: 6.45 s\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [20  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [20  0  0  0  0]\n",
      " [20  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  980\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "sigmoid\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 244 ms, total: 15.1 s\n",
      "Wall time: 7.74 s\n",
      "confusion matrix\n",
      " [[ 0 10  0  0  4]\n",
      " [ 0 11  4  0  6]\n",
      " [ 0  9  8  0  8]\n",
      " [ 0  8  5  0  8]\n",
      " [ 0  1  6  0 14]]\n",
      "Weighted Confusion Matrix Score:  1034\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "sigmoid\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 203 ms, total: 15.1 s\n",
      "Wall time: 7.72 s\n",
      "confusion matrix\n",
      " [[ 3  6  3  0  2]\n",
      " [ 4  6  6  0  5]\n",
      " [ 2  9  5  0  9]\n",
      " [ 1  5 10  1  4]\n",
      " [ 1  3  4  0 13]]\n",
      "Weighted Confusion Matrix Score:  1014\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "sigmoid\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 234 ms, total: 15.1 s\n",
      "Wall time: 7.78 s\n",
      "confusion matrix\n",
      " [[ 4  8  2  0  0]\n",
      " [ 1  9 10  0  1]\n",
      " [ 0 15  7  0  3]\n",
      " [ 1  5  9  0  6]\n",
      " [ 0  3  8  0 10]]\n",
      "Weighted Confusion Matrix Score:  892\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "sigmoid\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 297 ms, total: 15.6 s\n",
      "Wall time: 8.74 s\n",
      "confusion matrix\n",
      " [[ 5  5  4  0  0]\n",
      " [11  2  8  0  0]\n",
      " [ 5  5 13  0  2]\n",
      " [ 4  3  7  0  7]\n",
      " [ 1  2  9  0  9]]\n",
      "Weighted Confusion Matrix Score:  936\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "sigmoid\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.1 s, sys: 248 ms, total: 15.3 s\n",
      "Wall time: 7.95 s\n",
      "confusion matrix\n",
      " [[ 0  5  8  0  1]\n",
      " [ 0  8 12  0  1]\n",
      " [ 0  7 14  0  4]\n",
      " [ 0  5 11  0  5]\n",
      " [ 0  2  6  0 12]]\n",
      "Weighted Confusion Matrix Score:  891\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "sigmoid\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 242 ms, total: 15.2 s\n",
      "Wall time: 7.83 s\n",
      "confusion matrix\n",
      " [[ 0  4  5  1  3]\n",
      " [ 0  5 11  0  5]\n",
      " [ 0  5  5  0 15]\n",
      " [ 0  4  5  0 12]\n",
      " [ 0  0  2  0 18]]\n",
      "Weighted Confusion Matrix Score:  1127\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "sigmoid\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 237 ms, total: 15.1 s\n",
      "Wall time: 7.76 s\n",
      "confusion matrix\n",
      " [[ 0 12  1  0  0]\n",
      " [ 0 18  0  2  1]\n",
      " [ 0 20  2  2  1]\n",
      " [ 0 11  3  4  3]\n",
      " [ 0  6  1  8  5]]\n",
      "Weighted Confusion Matrix Score:  828\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "sigmoid\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 235 ms, total: 15.2 s\n",
      "Wall time: 7.8 s\n",
      "confusion matrix\n",
      " [[ 0 10  3  0  0]\n",
      " [ 0 15  3  0  3]\n",
      " [ 0  8  8  0  9]\n",
      " [ 0  4  4  0 12]\n",
      " [ 0  1  8  0 11]]\n",
      "Weighted Confusion Matrix Score:  973\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "sigmoid\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/755"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 234 ms, total: 15.1 s\n",
      "Wall time: 7.77 s\n",
      "confusion matrix\n",
      " [[ 0 10  2  0  1]\n",
      " [ 0  7 13  0  0]\n",
      " [ 0  6 16  0  3]\n",
      " [ 0  3 13  0  4]\n",
      " [ 0  3 11  0  6]]\n",
      "Weighted Confusion Matrix Score:  798\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "sigmoid\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 241 ms, total: 15.2 s\n",
      "Wall time: 7.8 s\n",
      "confusion matrix\n",
      " [[ 0 13  0  0  0]\n",
      " [ 0 15  4  0  1]\n",
      " [ 0  8 11  0  6]\n",
      " [ 0  4 11  0  5]\n",
      " [ 0  5  5  0 10]]\n",
      "Weighted Confusion Matrix Score:  862\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "linear\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 s, sys: 228 ms, total: 14.3 s\n",
      "Wall time: 7.32 s\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [21  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1020\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "linear\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 s, sys: 240 ms, total: 14.4 s\n",
      "Wall time: 7.4 s\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [21  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1020\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "linear\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 s, sys: 327 ms, total: 15.4 s\n",
      "Wall time: 8.68 s\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [21  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1020\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "linear\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 326 ms, total: 15.5 s\n",
      "Wall time: 9 s\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [21  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1020\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "linear\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 333 ms, total: 15.7 s\n",
      "Wall time: 9.12 s\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [20  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1010\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "linear\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 217 ms, total: 13.9 s\n",
      "Wall time: 7.15 s\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [20  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1000\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "linear\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 s, sys: 261 ms, total: 14.4 s\n",
      "Wall time: 7.59 s\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [20  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1000\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "linear\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 s, sys: 486 ms, total: 17.9 s\n",
      "Wall time: 12.3 s\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [21  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [20  0  0  0  0]\n",
      " [20  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  990\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "linear\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/755/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 318 ms, total: 15.1 s\n",
      "Wall time: 8.11 s\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [20  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [20  0  0  0  0]\n",
      " [20  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  980\n",
      "---------------------------------\n",
      "\n",
      "cross\n",
      "linear\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 s, sys: 372 ms, total: 15.9 s\n",
      "Wall time: 8.76 s\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [20  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [20  0  0  0  0]\n",
      " [20  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  980\n",
      "---------------------------------\n",
      "Best Score:  798\n",
      "Best cost:  cross\n",
      "Best Non-Linearity:  sigmoid\n"
     ]
    }
   ],
   "source": [
    "with np.errstate(all='ignore'):\n",
    "\n",
    "    nonlinearities = [\"sigmoid\",\"linear\"]\n",
    "    costs = ['quadratic','cross']\n",
    "    \n",
    "    custom_performances = []\n",
    "    lowest_score = 10000\n",
    "    best_cost = \"\"\n",
    "    best_nonlin = \"\"\n",
    "for cost in costs:\n",
    "    for nonlinearity in nonlinearities:\n",
    "\n",
    "        vals = {'n_hidden':50, \n",
    "                     'C':1e-2, 'epochs':75, 'eta':0.001, \n",
    "                     'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "                     'shuffle':True,'random_state':1, \n",
    "                       'nonlinearity': nonlinearity}\n",
    "        for train_indices, test_indices in cv_object.split(X,y): \n",
    "                    print(\"---------------------------------\")\n",
    "                    print(\"\")\n",
    "                    print(cost)\n",
    "                    print(nonlinearity)\n",
    "                    # I will create new variables here so that it is more obvious what \n",
    "                    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "                    # but it makes this code less readable)\n",
    "                    X_train = (X[train_indices])\n",
    "                    y_train = y[train_indices]\n",
    "\n",
    "                    X_test = (X[test_indices])\n",
    "                    y_test = y[test_indices]\n",
    "                    \n",
    "                    if(cost == \"quadratic\"):\n",
    "                        nn_long_sigmoid = TLPGaussianInitialQuad(**vals)\n",
    "                    else:\n",
    "                        print(\"in\")\n",
    "                        nn_long_sigmoid = TLPGaussianInitial(**vals)\n",
    "\n",
    "                    #%time nn_long_sigmoid.fit(X_train, y_train, print_progress=1, XY_test=(X_test,y_test))\n",
    "                    %time nn_long_sigmoid.fit(X_train, y_train, print_progress=1)\n",
    "                    y_hat = nn_long_sigmoid.predict(X_test) # get test set precitions\n",
    "\n",
    "                    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "                    acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "            #         lr_clf_accuracies.append(acc)\n",
    "            #         cost_accuracies.append([acc])\n",
    "\n",
    "                    conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "        #             print(vals)\n",
    "#                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "#                     plt.show()\n",
    "                    print(\"confusion matrix\\n\",conf)\n",
    "                    score = get_confusion_costTot(conf, cost_matrix)\n",
    "                    print(\"Weighted Confusion Matrix Score: \", score)\n",
    "                    custom_performances.append(score)\n",
    "                    if(score < lowest_score): \n",
    "                        lowest_score=score\n",
    "                        best_cost=cost\n",
    "                        best_nonlin=nonlinearity\n",
    "\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "print(\"Best Score: \",lowest_score)               \n",
    "print(\"Best cost: \",best_cost)\n",
    "print(\"Best Non-Linearity: \",best_nonlin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the hyper-parameters CHECK RANGE FOR HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_neurons = np.linspace(150, 200, num=10)\n",
    "hidden_neurons.sort()\n",
    "\n",
    "costs = np.logspace(-3,1, num=10)\n",
    "costs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with np.errstate(all='ignore'):\n",
    "    param_grid_input = {'n_hidden': hidden_neurons, 'C': costs}\n",
    "    gscv = GridSearchCV(cv= cv_object, estimator=nn_long_sigmoid, param_grid= param_grid_input, scoring= confusion_scorer,refit=False)\n",
    "    gscv.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using our scoring method using mentioned earlier to determine the best values for our hyperameters C (costs), and n_hidden (number of neurons in the hidden layer). With GridSearch, we will exhausitvely test our hyperamters and see which gives us our best score (mentioned under Evaluation above). We decided to use only two hyper parameters because our laptops were taking large amounts of time once we included three hyperparamters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing our MLP Implementation with that of Scikit Learn  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.64 s, sys: 48.8 ms, total: 2.69 s\n",
      "Wall time: 1.39 s\n",
      "confusion matrix\n",
      " [[ 0  2 12  0  0]\n",
      " [ 0  3 18  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  1 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  714\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.245098039216\n",
      "confusion matrix\n",
      " [[ 2 12  0  0  0]\n",
      " [ 3 18  0  0  0]\n",
      " [ 0 25  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 1 20  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.88 s, sys: 83.7 ms, total: 2.96 s\n",
      "Wall time: 1.93 s\n",
      "confusion matrix\n",
      " [[ 0  1 13  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 21  0  0]]\n",
      "Weighted Confusion Matrix Score:  714\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.245098039216\n",
      "confusion matrix\n",
      " [[ 1 13  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0 25  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0 21  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.3 s, sys: 93.7 ms, total: 3.39 s\n",
      "Wall time: 2.34 s\n",
      "confusion matrix\n",
      " [[ 0  0 14  0  0]\n",
      " [ 0  1 20  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 21  0  0]]\n",
      "Weighted Confusion Matrix Score:  714\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.245098039216\n",
      "confusion matrix\n",
      " [[ 0 14  0  0  0]\n",
      " [ 1 20  0  0  0]\n",
      " [ 0 25  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0 21  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.29 s, sys: 99.6 ms, total: 3.39 s\n",
      "Wall time: 2.42 s\n",
      "confusion matrix\n",
      " [[ 0  1 13  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 21  0  0]]\n",
      "Weighted Confusion Matrix Score:  714\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.245098039216\n",
      "confusion matrix\n",
      " [[ 1 13  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0 25  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0 21  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.26 s, sys: 91.3 ms, total: 3.35 s\n",
      "Wall time: 2.37 s\n",
      "confusion matrix\n",
      " [[ 0  0 14  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  707\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.247524752475\n",
      "confusion matrix\n",
      " [[ 0 14  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0 25  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0 20  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.5 s, sys: 38.6 ms, total: 2.54 s\n",
      "Wall time: 1.28 s\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  700\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.25\n",
      "confusion matrix\n",
      " [[ 0 13  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0 25  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0 20  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.01 s, sys: 90.4 ms, total: 3.1 s\n",
      "Wall time: 1.97 s\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  700\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.25\n",
      "confusion matrix\n",
      " [[ 0 13  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0 25  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0 20  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.8 s, sys: 73.2 ms, total: 2.87 s\n",
      "Wall time: 1.53 s\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 20  0  0]\n",
      " [ 0  0 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  693\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.252525252525\n",
      "confusion matrix\n",
      " [[ 0 13  0  0  0]\n",
      " [ 0 21  0  0  0]\n",
      " [ 0 25  0  0  0]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0 20  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.45 s, sys: 37.6 ms, total: 2.49 s\n",
      "Wall time: 1.26 s\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 20  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 20  0  0]\n",
      " [ 0  0 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  686\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.255102040816\n",
      "confusion matrix\n",
      " [[ 0 13  0  0  0]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0 25  0  0  0]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0 20  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.46 s, sys: 35.1 ms, total: 2.49 s\n",
      "Wall time: 1.26 s\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 20  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 20  0  0]\n",
      " [ 0  0 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  686\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.255102040816\n",
      "confusion matrix\n",
      " [[ 0 13  0  0  0]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0 25  0  0  0]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0 20  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  686\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "vals = {'n_hidden':50, \n",
    "         'C':1e-2, 'epochs':15, 'eta':0.001, \n",
    "         'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "         'shuffle':True,'random_state':1, \n",
    "           'nonlinearity': \"sigmoid\"}\n",
    "custom_performances = []\n",
    "custom_times = []\n",
    "custom_mem = []\n",
    "sk_performances = []\n",
    "sk_times = []\n",
    "sk_mem = []\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "            \n",
    "            # I will create new variables here so that it is more obvious what \n",
    "            # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "            # but it makes this code less readable)\n",
    "            X_train = (X[train_indices])\n",
    "            y_train = y[train_indices]\n",
    "\n",
    "            X_test = (X[test_indices])\n",
    "            y_test = y[test_indices]\n",
    "\n",
    "            nn_long_sigmoid = TLPGaussianInitialQuad(**vals)\n",
    "           \n",
    "\n",
    "            #%time nn_long_sigmoid.fit(X_train, y_train, print_progress=1, XY_test=(X_test,y_test))\n",
    "            st = time.time()\n",
    "\n",
    "            mem = memory_usage((nn_long_sigmoid.fit,(X_train,y_train))) # train object\n",
    "            t = (time.time() -st)\n",
    "            custom_times.append(t)\n",
    "            custom_mem.append(mem[0])\n",
    "\n",
    "            %time nn_long_sigmoid.fit(X_train, y_train, print_progress=1)\n",
    "            y_hat = nn_long_sigmoid.predict(X_test) # get test set precitions\n",
    "\n",
    "            # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "            acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "    #         lr_clf_accuracies.append(acc)\n",
    "    #         cost_accuracies.append([acc])\n",
    "\n",
    "            conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "#             print(vals)\n",
    "#                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "#                     plt.show()\n",
    "            print(\"confusion matrix\\n\",conf)\n",
    "            score = get_confusion_costTot(conf, cost_matrix)\n",
    "            print(\"Weighted Confusion Matrix Score: \", score)\n",
    "            custom_performances.append(score)\n",
    "            \n",
    "            clf = MLPClassifier(hidden_layer_sizes=(50, ), \n",
    "                        activation='relu', # type of non-linearity, every layer\n",
    "                        solver='sgd', \n",
    "                        alpha=1e-4, # L2 penalty\n",
    "                        batch_size= 'auto', # min of 200, num_samples\n",
    "                        learning_rate='constant', # adapt learning? only for sgd\n",
    "                        learning_rate_init=0.1, # only SGD\n",
    "                        power_t=0.0,    # only SGD with inverse scaling of learning rate\n",
    "                        max_iter=75, # stopping criteria\n",
    "                        shuffle=True, \n",
    "                        random_state=1, \n",
    "                        tol=0, # for stopping\n",
    "                        verbose=False, \n",
    "                        warm_start=False, \n",
    "                        momentum=0.9, # only SGD\n",
    "                        nesterovs_momentum=False, # only SGD\n",
    "                        early_stopping=False, \n",
    "                        validation_fraction=0.0, # only if early_stop is true\n",
    "                        beta_1=0.9, # adam decay rate of moment\n",
    "                        beta_2=0.999, # adam decay rate of moment\n",
    "                        epsilon=1e-08) # adam numerical stabilizer\n",
    "            \n",
    "            print(\"SCIKIT*****\")\n",
    "            \n",
    "            st = time.time()\n",
    "\n",
    "            mem = memory_usage((clf.fit,(X_train,y_train))) # train object\n",
    "            t = (time.time() -st)\n",
    "            sk_times.append(t)\n",
    "            sk_mem.append(mem[0])\n",
    "#             %time clf.fit(X_train,y_train)\n",
    "            yhat = clf.predict(X_test)\n",
    "            print('Validation Acc:',accuracy_score(yhat,y_test))\n",
    "            conf = mt.confusion_matrix(y_test,y_hat)\n",
    "                    #             print(vals)\n",
    "            #                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "            #                     plt.show()\n",
    "            print(\"confusion matrix\\n\",conf)\n",
    "            score = get_confusion_costTot(conf, cost_matrix)\n",
    "            print(\"Weighted Confusion Matrix Score: \", score)\n",
    "            sk_performances.append(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Implementations in terms of Generalization Performance, Computation Time, and Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[732, 717, 717, 717, 707, 700, 700, 693, 686, 686]\n",
      "[714, 714, 714, 714, 707, 700, 700, 693, 686, 686]\n"
     ]
    }
   ],
   "source": [
    "print(sk_performances)\n",
    "print(custom_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9726.129508018494\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEJCAYAAABlmAtYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110889b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110889780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([sk_performances,custom_performances])\n",
    "plt.title(\"Comparing Generalization Perfomances\")\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Generalization Performances')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()\n",
    "print((time.time() -st)*100)\n",
    "# ax = fig.add_subplot(111)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that both implementations score similar values based on our scorer method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110846a58>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110846b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110846a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([sk_times,custom_times])\n",
    "plt.title(\"Comparing Computation Times\")\n",
    "plt.xlabel('Implementation')\n",
    "plt.ylabel('Training Time (seconds) ')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite our performance scores being similar, SKL is much faster than our custom implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11030b0f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEaCAYAAADg2nttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XlcVPX+P/DXGYZFBEZgRBNUxC0xF3BJRFxKv1ezqCxR\nUq+URopi2r1WV0vLFS5hpgFhLrgFGoppmY/vF64K7hCaN3DBfQFlVRECBub8/vDB/JwA5wAzzCiv\n5+Ph4zHzOefMec9wnNecz+csgiiKIoiIiJ5AZuwCiIjI9DEsiIhIJ4YFERHpxLAgIiKdGBZERKQT\nw4KIiHRiWBBJEBMTA7lcbuwyiIyGYUF6U1BQgI8//hjdu3eHlZUVnJycMHToUGzZsgWVlZXGLq9R\nJkyYgNu3bzfJumJiYiAIAtq2bQuVSqU1LS8vD5aWlhAEAUeOHGmSeogAgD+VSC9u3ryJIUOGQC6X\nY8mSJfDw8IC5uTmOHTuGr776Cr1790bfvn2NXWa9iaKIyspKtGjRAi1atGiy9ZqZmUEul2Pfvn0Y\nN26cpn3Tpk147rnncP369Sarpb5UKhXMzc2NXQbpGfcsSC+CgoJQXl6O9PR0TJo0Ce7u7ujatSum\nTp2K3377DV27dgXw6Ivk008/hbOzMywsLODu7o4ffvhB67UEQcDatWsxYcIEtGzZEh06dEB8fDzu\n37+PSZMmwdbWFm5ubti1a5dmmWvXrkEQBGzbtg0vv/wyWrRoATc3N8TFxWm99sKFC9GjRw9YW1uj\nffv2mDFjBu7fv6+ZXt3ddPDgQXh4eMDS0hKJiYk1uqGqnx89ehSenp6wtrZGv379kJqaqrW+pKQk\n9OrVC1ZWVujbty9SUlI0dery3nvv4fvvv9c8F0UR69evx7Rp02rMe/fuXQQEBKB169awtbWFt7c3\nkpOTNdMPHToEQRCwf/9+eHl5oUWLFujXrx8yMjKQkZGBIUOGwNraGgMHDkRmZqbWa+/fvx/9+vWD\npaUlnJycEBQUhJKSEs30gIAAjBw5EmvXroWrqyssLS0RFRWFVq1aobS0VOu1lixZgq5du4IXjngK\niUSNVFBQIMpkMnHp0qU65/3nP/8pOjg4iDt37hQvXLggLl++XBQEQUxMTNTMA0Bs06aNGBMTI2Zl\nZYkzZ84UraysxNGjR4ubNm0Ss7KyxNmzZ4vW1tZifn6+KIqiePXqVRGA+Nxzz4nbtm0Tz58/Ly5c\nuFCUyWRienq65rWXLl0qJicni1evXhUTExPF7t27i3//+9810zdt2iQKgiAOGDBA/M9//iNevnxZ\nzM3NFTdt2iSamZnVmM/Hx0dMTk4Wz507J44ePVp0dXUVVSqVKIqieOvWLbFFixbitGnTxIyMDDEx\nMVH09PQUAYhbt26t8zOqXtf169dFuVwuXr9+XRRFUUxKShLt7e3FzMxMEYCYkpIiiqIolpaWij16\n9BDHjRsnpqamillZWeKyZctECwsLMTMzUxRFUTx48KAIQOzbt6+YlJQkZmRkiIMGDRJ79eol+vj4\niImJiWJmZqbo7e0tDhw4UFPL77//LpqZmYlz584Vz507J+7fv19s3769OHnyZM08U6dOFW1tbcU3\n3nhDPHPmjHj27Fnx4cOHYqtWrcSYmBjNfFVVVWLHjh3FkJAQndsJmR6GBTXayZMnRQDirl27njhf\nSUmJaGFhIUZERGi1v/HGG+KIESM0zwGIH374oeZ5bm6uCECcPXu2pq2wsFAEIO7bt08Uxf8fFp99\n9pnWa3t5eWl9sf3V7t27RQsLC7GqqkoUxUdf1ADE5ORkrflqCwsA4m+//aZpO3HihAhAPH/+vCiK\norhgwQKxY8eOYmVlpWaeX3/9VXJYiKIojhkzRly0aJEoiqI4YcIEMTg4WPNeq8Ni06ZNorOzsyak\nqo0YMULzOVaHRUJCgmb6zp07RQBifHy81ucBQCwuLhZFURQnT54sDhgwQOt19+zZIwqCIF67dk0U\nxUdhoVAoNMtUCw4OFr29vTXPDxw4IJqbm4t3796t872T6WI3FDWaKLFL4dKlS6ioqMDQoUO12ocN\nG4aMjAyttj59+mget27dGmZmZujdu7emzd7eHhYWFsjNzdVazsvLS+u5t7e31mvv3r0bQ4cORbt2\n7WBjY4NJkyahoqICd+7c0VpuwIABOt+PIAhadbZr1w7Aoy4hAMjMzMSAAQNgZmZWZ326BAYGYuPG\njbh79y4SEhLw/vvv15gnNTUVd+7cQatWrWBjY6P5l5KSgqysLK15H6+3bdu2AKD1uVa3VX+uGRkZ\ntf69RFHU6q7q0aMHbGxstOb74IMPcPToUZw7dw4A8P3338PX1xdOTk71+gzINDAsqNG6du0KmUxW\no6+7MWobIP1rmyAIUKvVkl/z5MmTGD9+PIYOHYqEhASkp6fju+++AwBUVFRo5jMzM4OVlZXO15PJ\nZFpBIAgCAGjVVN3WUK+++irUajUmTZoET09P9OrVq8Y8arUaPXr0wJkzZ7T+nTt3TmvMA9D+DKtr\nq62tPp8rALRs2bJGW8+ePTFkyBB8//33yM3Nxd69exEYGFiv1yXTwbCgRnNwcMCYMWPw7bffag0W\nV1OpVCgpKUGXLl1gaWmpNfAKAIcPH8YLL7ygl1pOnDih9fzYsWNwd3cHABw5cgRKpRLLli3Diy++\niG7duuHWrVt6WW9t3N3dkZqaiqqqqjrr00Uul+O9995DUlJSrXsVANC/f39cuXIFdnZ26NKli9a/\n6r2dhurZs2etfy9BENCzZ0+dy3/wwQfYsmUL1q1bB2dnZ4waNapR9ZDxMCxILyIjI2Fubo5+/frh\nhx9+QGZmJi5duoRt27ahf//+yMrKgrW1NebMmYPPP/8cP/74Iy5evIgVK1bgp59+woIFC/RSx4YN\nG/DDDz/g4sWLWLRoEY4fP46PPvoIANC9e3fk5eVhw4YNuHLlCrZs2YLIyEi9rLc2QUFBuHv3LmbO\nnIlz587h4MGDWLhwIYD67XEsWrQIeXl5mDp1aq3TJ02ahE6dOmHs2LH43//9X1y7dg0nT57EypUr\nsWfPnka9h/nz5yM9PR3z5s3D+fPnceDAAQQHB2PSpEno0KGDzuXffvttAMDSpUsxffr0Ru9pkfEw\nLEgvOnTogPT0dLzxxhv44osv4OnpicGDByM6OhozZszQ7DksX74c77//PubOnYsXXngB27Zt0xzu\nqg8hISFYt24devfuja1bt2Lbtm3w9PQE8KhLZ+HChViwYAF69eqFuLg4hIWF6WW9tXF2dsbevXtx\n7Ngx9O3bFx9++CGWLl0KAJK6uaqZm5tDqVRqdXk9zsrKCocPH0b//v3x7rvvolu3bhg3bhxOnTqF\njh07Nuo99O7dG3v37kVycjL69OmDKVOmYOzYsZruO12srKwwZcoUqNVqvPfee42qhYxLEKWOThKZ\nsGvXrqFTp05ISUnBkCFDjF1OnZKTkzFs2DCcPXu21vGHZ5Gfnx9UKhUSEhKMXQo1As/gJjKgqKgo\n9OnTB+3atUNmZibmzZuHF198sVkERVFREU6dOoWEhAQkJSUZuxxqJIYFkQFdv34dK1euxN27d9G2\nbVuMGjUKoaGhxi6rSXh4eGiuF/bXw2/p6cNuKCIi0okD3EREpBPDgoiIdHqmxiyys7ONXcIzQ6lU\nIj8/39hlENXAbVO/pJ64yT0LIiLSiWFBREQ6MSyIiEgnhgUREenEsCAiIp0YFkREpBPDgoiIdGJY\nEBGRTs/USXlUf87OzvVe5vbt2waohIhMGcOimavri9/Z2ZmhQEQa7IYiIiKduGdBRCapIV2kALtJ\nDYVhQUQmiV2kpqVJwiIyMhLp6elQKBQIDw8HAMTFxSEtLQ2CIEChUCAoKAgODg6orKzEd999h6tX\nr0KtVmPo0KF48803m6JMIiKqQ5OMWQwfPhwLFizQavP19cVXX32FsLAweHp6Ij4+HgBw4sQJVFZW\nIjw8HCEhIUhMTERubm5TlElERHVokrBwd3eHjY2NVpu1tbXmcXl5OQRB0DwvKytDVVUVKioqIJfL\nteYlIqKmZ9Qxi9jYWCQnJ8Pa2hqLFy8GAAwaNAhpaWkIDAxERUUFpk6dWiNoqiUmJiIxMREAEBIS\nAqVS2WS1Nwf8PMlUcdtsekYNC39/f/j7+yMhIQEHDhyAn58fLl26BJlMhujoaJSUlGDRokXo1asX\n2rRpU2P5kSNHYuTIkZrnvHuWfvHzJFPFbVN/nqo75fn4+ODkyZMAgCNHjqBv376Qy+VQKBTo3r07\nLl++bOQKiYiaN6OFRU5OjuZxamqqJt2USiX++OMPAI/GLrKyshp8vDUREemHIIqiaOiVrF69GpmZ\nmSguLoZCoYCfnx/S09ORk5MDQRCgVCoRGBgIBwcHlJWVITIyErdu3YIoihgxYgR8fX0lrSc7O9vA\n76T54LHsZKq4beqX1G6oJgmLpsKw0B/+hyRTxW1Tv56qMQsiIjJtDAsiItKJYUFERDoxLIiISCeG\nBRER6cSwICIinRgWRESkE8OCiIh0YlgQEZFODAsiItKJYUFERDoxLIiISCeGBRER6cSwICIinRgW\nRESkE8OCiIh0YlgQEZFODAsiItKJYUFERDoxLIiISCeGBRER6cSwICIinRgWRESkE8OCiIh0kjfF\nSiIjI5Geng6FQoHw8HAAQFxcHNLS0iAIAhQKBYKCguDg4ICUlBTs3btXs+yNGzcQGhoKV1fXpiiV\niIhqIYiiKBp6JZmZmbCyskJERIQmLEpLS2FtbQ0A2L9/P27duoXAwECt5W7cuIGwsDCsXbtW0nqy\ns7P1W3gz5uzsjNu3bxu7DKIauG3qV7t27STN1yTdUO7u7rCxsdFqqw4KACgvL4cgCDWWO3LkCAYP\nHmzw+oiI6MmMOmYRGxuLmTNn4siRI5gwYUKN6cePH4e3t7cRKiMiosfpHLO4f/8+fv/9d1y7dk3T\ndeTq6orevXujVatWjVq5v78//P39kZCQgAMHDsDPz08zLSsrCxYWFujQoUOdyycmJiIxMREAEBIS\nAqVS2ah6SBs/TzJV3DabXp1hcevWLezYsQMZGRlwc3ODs7MzWrVqhT///BPJycmIiYlBz549MWHC\nBLi4uDSqCB8fH6xcuVIrLI4ePapzr2LkyJEYOXKk5nl+fn6j6iBt/DzJVHHb1B+pYxZ1hkVkZCR8\nfX0xZ84cmJub15iuUqmQlpaGqKgoLF++vN4F5uTk4LnnngMApKamahWsVqtx/PhxLFmypN6vS0RE\n+ldnWKxYseKJC5qbm8PLywteXl46V7J69WpkZmaiuLgYM2bMgJ+fH9LT05GTkwNBEKBUKrWOhDp3\n7hyUSiXatGlTj7dCRESGIvnQWbVajYsXL6KoqAj29vbo1q0bZDLTOqePh87qDw9PJFPFbVO/Gt0N\n9bjr168jLCwMKpUKDg4OKCwshLm5Of75z3/yZDkiomZAUlhERUXhb3/7G1599VUIggBRFPHLL78g\nKioKoaGhhq6RiIiMTFI/Uk5ODsaOHas5cU4QBLzyyiu4c+eOQYsjIiLTICksPDw8kJaWptWWlpYG\nDw8PgxRFRESmpc5uqLVr12r2JNRqNVavXg03Nzc4OjqioKAAV65cQf/+/ZusUCIiMp46w6Jt27Za\nz9u3b6957OLigj59+hiuKiIiMilNctXZpsJDZ2vXs2dP3Lt3z+DradWqFTIyMgy+HmreeOisfun1\n0FkAyMvLw/Xr11FWVqbVPmTIkPpVRk3u3r179f7PpVQq631JBWdn53rNT0RPD0lhkZCQgF27dsHF\nxQUWFhaadkEQGBZERM2ApLD4+eefERIS0ugLBhIR0dNJ0qGzNjY2aN26taFrISIiEyVpzyIgIADR\n0dEYO3YsFAqF1jReV56I6NknKSwqKytx9uxZHD16tMa0HTt26L0oIiIyLZLCYv369fD394e3t7fW\nADcRETUPksJCrVZjxIgRJndJciIiahqSvv1fe+017NmzB8/Q+XtERFQPkvYsfv31V9y7dw8JCQmw\nsbHRmhYVFWWQwoiIyHRICovg4GBD10FERCZMUli4u7sbug4iIjJhdY5Z7N+/HyqV6okLq1Qq7N+/\nX+9FERGRaalzz+LevXuYM2cOPDw84O7ujnbt2sHKygplZWXIzs5GZmYmTp8+jWHDhjVlvUREZAR1\nhsU777yDV199FYcOHcJ//vMf3LhxAyUlJbCxsUGHDh3g4eEBf39/2NraNmW9RERkBE8cs7Czs4Ov\nry98fX2bqh4iIjJBPMuOiIh0YlgQEZFOku+U1xiRkZFIT0+HQqFAeHg4ACAuLg5paWkQBAEKhQJB\nQUFwcHAAAFy/fh3r1q3Dn3/+CUEQsHLlSl6TiojIiJokLIYPH47Ro0cjIiJC0+br64uJEycCeHSY\nbnx8PAIDA1FVVYW1a9di9uzZcHV1RXFxMeTyJimTiIjqILkbqri4GMnJyfjpp58AAIWFhSgoKJC0\nrLu7e43LhFhbW2sel5eXQxAEAMDvv/+ODh06wNXVFQBga2vLCxgSERmZpJ/smZmZCA8Ph5ubGy5c\nuIDXX38dd+7cwd69e/Hpp582eOWxsbFITk6GtbU1Fi9eDADIycmBIAhYvnw5Hjx4gMGDB+P111+v\ndfnExEQkJiYCAEJCQngjpieo72cjl8sb9Hnyb0BNgdtZ05MUFjExMZg7dy569eqFd999FwDQpUsX\nXL58uVEr9/f3h7+/PxISEnDgwAH4+fmhqqoK58+fx8qVK2FpaYklS5bAzc0NvXr1qrH8yJEjMXLk\nSM3z/Pz8RtXzLKvvZ6NUKhv0efJvQE2B25n+tGvXTtJ8kvp38vLyanxZy+VyVFVV1b+yWvj4+ODk\nyZMAAEdHR/To0QN2dnawtLSEh4cHrl69qpf1EBFRw0gKCxcXF5w5c0ar7b///S86dOjQ4BXn5ORo\nHqempmrSrU+fPrh58ybKy8tRVVWFc+fOwcXFpcHrISKixpPUDTVlyhSEhobCw8MDFRUVWLduHX77\n7TfMnz9f0kpWr16NzMxMFBcXY8aMGfDz80N6erpmfEKpVCIwMBAAYGNjg7Fjx+Jf//oXBEGAh4cH\nPD09G/4OiYio0QRR4u3vCgsLkZKSgry8PCiVSvj4+MDR0dHQ9dVLdna2sUswSc7Ozrh9+3a9lmnI\nmEVD1kNUX9zO9EvqmIXkExgcHBzqPCqJiIiebZLCYu3atZrzILQWlsvh6OiIAQMGaM6LICKiZ4+k\nAW5ra2ukpqZCFEU4ODhAFEWkpaVBJpPh9u3b+Oyzz3D48GFD10pEREYiac8iJycH//rXv/D8889r\n2i5evIgdO3bg888/x5kzZxATE8MbIRFRvfXs2RP37t2r1zLOzs71mr9Vq1bIyMio1zKkTVJYZGVl\noWvXrlptbm5uuHTpEoBHh7tKvfQHEdHj7t27V68B64YefEGNI6kbytXVFbGxsaioqAAAVFRUYMeO\nHZpxitzc3BrXfiIiomeHpD2LWbNmYc2aNZg6dSpsbGzw8OFDdO7cGXPmzAEAPHz4ENOnTzdooURE\nZDySwsLJyQnLli1Dfn4+ioqKYG9vr3Uhr86dOxusQCIiMr563ShCqVTC0dERoihCrVYDAC8fTkTU\nDEgKi8LCQmzYsAHnzp1DSUmJ1rQdO3YYpDAiIjIdksJi3bp1sLS0xKJFi7B48WJ8+eWX+PHHH+Hh\n4WHo+kgP+v87Ca9vP98k6yGiZ5OksLh48SIiIyNhZWUFQRDg6uqKmTNn4rPPPtO6nwSZprSPX26y\na0NhEq/ZQ/QskjTgIJPJYGZmBgBo2bIlHjx4AEtLSxQWFhq0OCIiMg2S9iy6dOmC06dPY+DAgejT\npw++/vprWFhY8CgoIqJmQlJYBAcHo/pK5gEBAdi7dy/KysowduxYgxZHRESmQVJYtGzZUvPYwsIC\nb7/9tsEKIiIi0yNpzOLnn3/GtWvXADwa7J45cyZmzZqFixcvGrI2IiIyEZLC4pdffoGTkxMAIDY2\nFq+++ireeustxMTEGLI2IiIyEZLCorS0FNbW1vjzzz9x7do1jBkzBi+99BJvY0pE1ExIGrNwdHTE\nhQsXcPPmTfTo0QMymQylpaW81AcRUTMhKSwmT56MVatWQS6X4x//+AcAID09HV26dDFocUREZBok\nhYWnpyeio6O12gYNGoRBgwYZpCgiIjItTwyLP/74o0abmZkZWrdurXWJciIierY9MSyioqJqtFVV\nVeH+/fvo0qUL5s2bBwcHB4MVR0REpuGJYREREVFre3l5ObZv346YmBh89NFHBimMiIhMR71uflTN\n0tIS77zzjua2qrpERkYiPT0dCoUC4eHhAIC4uDikpaVBEAQoFAoEBQXBwcEBubm5mDdvHtq1awcA\n6Nq1KwIDAxtSJhER6UmDwgJ4NHZRVVUlad7hw4dj9OjRWnsqvr6+mDhxIgBg//79iI+P14RC27Zt\nERYW1tDSiIhIzxp8osQvv/wCNzc3SfO6u7vDxsZGq83a2lrzuLy8HIIgNLQUIiIysCfuWSxatKjG\nl3hlZSXy8/NhYWGBTz/9tFErj42NRXJyMqytrbF48WJNe25uLubPnw9ra2tMnDgRPXr0qHX5xMRE\nJCYmAgBCQkJ4hNYT1PezkcvlDfo8+TeghqjPdsNt0zgEsfra47U4dOhQjTYzMzMolUp07doVcrn0\nXqzc3FyEhoZqxiwel5CQAJVKBT8/P6hUKpSVlcHW1hZXrlxBWFgYwsPDtfZE6sLLj9TO2dm5ye6U\nV9/1ENV3u+G2qV/V48O6PPHbfvjw4fqoRScfHx+sXLkSfn5+MDc3h7m5OQDAzc0Nbdq0QU5ODm+0\nRERkREa7uFNOTo7mcWpqqibdHjx4ALVaDQC4e/cucnJy0KZNG6PUSEREjzT4aKj6WL16NTIzM1Fc\nXIwZM2bAz88P6enpyMnJgSAIUCqVmiOhMjMzsXPnTpiZmUEmk+H999+vMThORERNq0nCYu7cuTXa\nXnrppVrn5TWniIhMj6RuqOq75BERUfMkac9i6dKlcHBwgI+PD3x8fGBvb2/ouoiIyIRICot169Yh\nPT0dKSkp+PHHH9G9e3cMHToUL774IiwtLQ1dIxERGdkTz7OoTWlpKY4fP45ff/0Vubm5GDhwIEaO\nHInnn3/eUDVKxvMsasfzLMiUvb79fJOs56dJxv+OMkV6Oc/ir8rKynDq1CkcO3YMBQUFGDx4MJRK\nJdauXQsPDw9Mnz69QcUSUfOV9vHLTXJSHibxh0xjSAqL9PR0JCcn4/Tp03j++efx0ksv4ZNPPoGF\nhQUAYPTo0Zg5cybDgojoGSUpLLZv345hw4Zh6tSptQ5u29jYICAgQN+1ERGRidAZFmq1Gp06dcKY\nMWM0l+Gozcsvv6zXwoiIyHToPM9CJpPh7NmzvIQ4EVEzJumkvLFjx2Lnzp2orKw0dD1ERGSCJI1Z\nHDhwAPfu3cMvv/wCOzs7rWlRUVEGKYyIiEyHpLAIDg42dB1ERGTCJIWFu7u7oesgIiITJiksKisr\nsXv3biQnJ6OoqAj29vYYOnQoxo0bV6+75RER0dNJ0jf9tm3bcPnyZbz//vto3bo18vLysGvXLpSW\nlvL8CiKiZkBSWJw4cQJhYWGwtbUF8OhaIp06dcL8+fMZFkREzYCkQ2frea1BIiJ6xkjas/Dy8kJo\naCjefvttzUW8du3aBS8vL0PXR0REJkBSWEyePBm7du3Chg0bNAPc3t7eeOuttwxdHxERmQBJYSGX\nyzFhwgRMmDDB0PUQEZEJknzca15eHq5fv46ysjKt9iFDhui9KCIiMi2SwiIhIQG7du2Ci4uL5h4W\nACAIAsOCiKgZkBQWP//8M0JCQuDi4mLoeoiIyARJOnTWxsYGrVu3NnQtRERkoiTtWQQEBCA6Ohpj\nx46FQqHQmqZUKg1SGBERmQ7J14Y6e/Ysjh49WmPajh07dC4fGRmJ9PR0KBQKhIeHAwDi4uKQlpYG\nQRCgUCgQFBQEBwcHzTL5+fmYN28exo8fD19fX6nvh4iIDEBSWKxfvx7+/v7w9vbWGuCWavjw4Rg9\nejQiIiI0bb6+vpg4cSIAYP/+/YiPj0dgYKBm+ubNm+Hh4VHvdRERkf5JCgu1Wo0RI0ZAJpM0xFGD\nu7s7cnNztdqsra01j8vLy7Vu23rq1Ck4OTnB0tKyQesjIiL9khQWr732Gvbs2YM333xTr/fijo2N\nRXJyMqytrbF48WIAQFlZGX766Sd8/vnn2Lt37xOXT0xMRGJiIgAgJCSE4ydP4OzsbPB12Nvb829A\nDWLo7ZPbZuMJooSrBM6cORP37t2DXC6HjY2N1jSpt1XNzc1FaGioZszicQkJCVCpVPDz88OWLVvQ\npUsXDB48GDt37oSVlZXkMYvs7GxJ85Fuzs7OuH37trHLIKqB26Z+tWvXTtJ8JnFbVR8fH6xcuRJ+\nfn64dOkSTp48ie3bt6OkpASCIMDCwgKjR482aA1ERFQ3o91WNScnB8899xwAIDU1VZNuS5Ys0cxT\nvWfBoCAiMi5JYaFSqRAfH4+jR4+iuLgYmzdvxu+//46cnBxJX+SrV69GZmYmiouLMWPGDPj5+SE9\nPR05OTkQBAFKpVLrSCgiIjItksJi8+bNKCwsxJw5c7BixQoAQPv27bF582ZJYTF37twabS+99JLO\n5fz8/KSUR0REBiYpLE6dOoU1a9bAyspKczSUg4MDCgsLDVocERGZBkknTsjlcqjVaq22Bw8eaO7J\nTUREzzZJYTFo0CB8++23mhPrioqKsGHDBgwePNigxRERkWmQFBbvvPMOnJyc8I9//AOlpaWYM2cO\n7O3tMX78eEPXR0REJkDSSXmPq+5+0ueZ3PrCk/L0hyc+kanitqlfejkpLz8/v9b2goICzWOeQk9E\n9Ox7YljMmjVL5wtIuUQ5ERE93Z4YFh07dkRFRQWGDRsGHx8frftNEBFR86FzzOLGjRs4fPgwjh07\nBhcXFwwdOhQvvvhig+5rYWgcs9Af9guTqeK2qV9SxywkD3Cr1WqcPXsWhw4dwpkzZ7Bo0SK4ubk1\nqkh9Y1iSwqNwAAAMmUlEQVToD/9DkqnitqlfUsNC8t2M7ty5g8zMTGRlZaFTp041LlVORETPrieO\nWTx8+BBHjhzB4cOHUVZWBh8fH3z55Zc8AoqIqJl5Ylh88MEHcHJygo+PD7p16wbg0R7GnTt3NPO8\n8MILhq2QiIiM7olh0apVK1RUVCApKQlJSUk1pguCgG+//dZgxRERkWl4YlhEREQ0VR1ERGTCJA9w\nExFR88WwICIinRgWRESkE8OCiIh0YlgQEZFODAsiItKJYUFERDoxLIiISCeGBRER6cSwICIinZ54\nuQ99iYyMRHp6OhQKBcLDwwEAcXFxSEtLgyAIUCgUCAoKgoODAy5duoTo6GjNsuPHj8fAgQObokwi\nIqqD5JsfNUZmZiasrKwQERGhCYvS0lJYW1sDAPbv349bt24hMDAQ5eXlkMvlMDMzQ1FREebPn4/o\n6GiYmZnpXA9vfqQ/vMEMmSpum/ql95sfNYa7u3uNmyVVBwUAlJeXQxAEAIClpaUmGFQqlaadiIiM\np0m6oeoSGxuL5ORkWFtbY/HixZr2rKwsREVFIS8vD8HBwXXuVSQmJiIxMREAEBISwpsy6Rk/TzJV\n3DabXpN0QwFAbm4uQkNDNd1Qj0tISIBKpYKfn59W+61btxAREYEvv/wSFhYWOtfBbij94a4+mSpu\nm/plUt1Quvj4+ODkyZM12l1cXGBlZYWbN28aoSoiIqpmtLDIycnRPE5NTdWkW25uLqqqqgAAeXl5\nyM7ORuvWrY1SIxERPdIkYxarV69GZmYmiouLMWPGDPj5+SE9PR05OTkQBAFKpRKBgYEAgPPnz2PP\nnj0wMzODTCbDtGnTYGdn1xRlEhFRHZpszKIpcMxCf9gvTKaK26Z+PVVjFkREZNoYFkREpBPDgoiI\ndGJYEBGRTgwLIiLSiWFBREQ6GfXaUEREdXF2dm7QNB5WaxgMCyIySXV96SuVSuTn5zdxNcRuKCIi\n0olhQUREOjEsiIhIJ4YFERHpxLAgIiKdGBZERKQTw4KIiHTieRbNXENOfOJJT0TND8OimeOJT0Qk\nBbuhiIhIJ4YFERHpxLAgIiKdGBZERKQTw4KIiHRiWBARkU4MCyIi0olhQUREOgmiKIrGLoKIiEwb\n9yyoVp9++qmxSyCqFbdN42BYEBGRTgwLIiLSiWFBtRo5cqSxSyCqFbdN4+AANxER6cQ9CyIi0olh\nQUREOvHmR83Y7t27ceTIEchkMgiCgMDAQGzfvh1TpkxB586dkZubi2XLluG9996Dubk59u3bx8MW\nSe8KCgqwYcMG3Lp1C6IowtPTE1OmTMGRI0dw+fJlTJs2TTPvF198odk+Z82aBSsrKwiCgJYtW2L2\n7Nlo3bo1gNq37a5duxrrLT4TGBbN1MWLF/Hbb78hNDQU5ubmePDgASorKzXTCwoKsHz5cvz9739H\n3759kZGRYcRq6VkliiK++uor/M///A8+/vhjqNVqREdHIzY2Fu3bt9e5/OLFi2FnZ4edO3di165d\nmDFjhs5tmxqG3VDNVFFREWxtbWFubg4AsLOzg4ODg2basmXL4O/vj/79+xuzTHrG/fHHH7CwsMCI\nESMAADKZDFOnTsXBgwdRXl4u+XW6deuGoqIiAE/etqnhGBbNVJ8+fVBQUIAPP/wQ69evR2ZmpmZa\nREQERo8ejUGDBhmxQmoObt68iU6dOmm1WVtbQ6lUoqqqSvLrnDlzBgMGDADw5G2bGo5h0UxZWVkh\nNDQUgYGBsLOzw9dff41Dhw4BAHr16oWUlJR6/bIj0reSkpJa2wVB0Dz+8ssv8cEHH+D06dPw9vYG\n8ORtmxqOYdGMyWQy9OzZE35+fpg2bRpOnDgBAHj99dfRuXNnrFq1ql6/7ojqy8XFBVevXtVqKy0t\nRX5+Pjp16lQjMB4+fAhbW1vN88WLFyMyMhKurq7YuXOnpr2ubZsajmHRTGVnZyMnJ0fz/Nq1a5oj\nSQAgICAALVq0QFRUFHjeJhlKr169UF5ejsOHDwMA1Go1tmzZguHDh6NLly64cOEC7t27BwC4fPky\nVCoVHB0dtV7DzMwMAQEBSE5OxsOHD3Vu29QwPIO7mbpy5Qo2btyIkpISmJmZoW3btggMDMSqVas0\nhyZWVlYiJCQEHTt2hKenJ1asWKH1q+6jjz5Ct27djPgu6FmQn5+P9evXIzs7G6IowsPDA1OmTIG5\nuTlSU1MRHx8PtVoNKysrvPvuu3BzcwMAzJo1CytXroSdnR0AYOPGjbCzs4Onp2et23b1fNQwDAsi\nItKJ3VBERKQTw4KIiHRiWBARkU4MCyIi0olhQUREOjEsqFnz8/PDnTt3jF2G3u3evRvfffedscug\nZwjDgkzerFmzcPbsWWOX0WR27tyJNWvWSJ4/IyMDM2bM0GobN25cjTaixmBYEBGRTryfBT1VDh06\nhKSkJHTu3BmHDh2CjY0NgoODkZOTgx07dkClUmHy5MkYPnw4gEdX0DU3N8fdu3eRlZWFTp06ad0k\n53EqlQqxsbE4fvw4KisrMWDAAAQEBMDCwgIZGRlYu3YtxowZg3379kEmk2H69OmQy+XYvHkzHjx4\ngNdeew3jxo0D8OiyFXv37kVSUhJKSkrwwgsvIDAwEDY2NsjNzcXs2bMRFBSEHTt2oKKiAmPHjsW4\nceNw5swZJCQkAABSU1PRtm1bhIWF4eDBg9i7dy8KCgpgZ2eH119/HaNGjUJZWRlWrFiByspKTJky\nBQDwzTffIDExEXfu3MGcOXMAAGlpafjhhx9QWFgIV1dXTJ8+HS4uLgAe7bn97W9/Q3JyMvLy8tC3\nb1/MmjULFhYWhv5z0lOEexb01MnKykLHjh2xceNGDBkyBKtXr8alS5ewZs0aBAcHY+PGjSgrK9PM\nf+TIEbz11lvYsGEDXF1d6+zi2b59O3JychAWFoY1a9agsLAQ8fHxmun37t2DSqXCd999Bz8/P0RH\nRyMlJQUhISFYsmQJdu3ahdzcXADAgQMHkJqaii+++ALR0dGwsbHB+vXrtdZ3/vx5fPPNN/j8888R\nHx+PW7duoW/fvnjzzTfh5eWFrVu3IiwsDACgUCjwySefYPPmzQgKCsLmzZtx5coVWFlZYcGCBbC3\nt8fWrVuxdevWGvduyM7OxjfffIOAgACsX78eHh4eCA0N1boh0PHjx7FgwQJERETgxo0bvEor1cCw\noKeOk5MTRowYAZlMhsGDB6OgoABvv/02zM3N0adPH8jlcq1Ba09PT7i7u8Pc3Bz+/v64ePEi8vPz\ntV5TFEUkJSVh6tSpsLGxQYsWLTBu3DgcPXpUM4+ZmRnGjRsHuVwOb29vFBcX45VXXkGLFi3Qvn17\nuLi44Nq1awCA//u//8PEiRPh6OgIc3NzjB8/HidPntS6iu/48eNhYWEBV1dXdOzYEdevX6/zPXt6\neqJt27YQBAHu7u7o3bs3zp8/L+nzOnbsGDw8PNC7d2/I5XK89tprqKiowIULFzTzjBkzBg4ODrCx\nsUG/fv0074OoGruh6KmjUCg0j6u7Slq1aqXV9viexeNXKbWysoKNjQ2KioqgVCo17Q8ePEB5ebnW\nPcZFUYRardY8t7W1hUwm01rvX2upXm9eXh6++uorrXsvyGQy3L9/X/P88ZotLS21av6r06dPIz4+\nXnOxvfLycnTo0KHO+R9XVFSk1e0mk8mgVCpRWFhYay0WFhZa04gAhgU1AwUFBZrHZWVlePjwIezt\n7bXmsbW1hYWFBVatWqWXW3A6Ojpi5syZeP7552tMq+6qqsvjAQM8GksJDw/H7Nmz0b9/f8jlcvz7\n3/+uc/6/sre3x40bNzTPRVFEfn4+bzVK9cJuKHrmnT59GufPn0dlZSXi4uLQrVs3rb0K4NGv7Zdf\nfhkxMTGaX/+FhYU4c+ZMg9Y5atQoxMXFIS8vD8CjPZfU1FRJyyoUCuTl5Wn2aiorK6FSqWBnZwcz\nMzOcPn1a61BihUKB4uJilJaW1vp6gwcPxunTp/Hf//4XlZWV2LdvH8zNzdG9e/cGvTdqnrhnQc88\nb29v/Pjjj7h48SLc3NwQHBxc63yTJk1CfHw8Fi5ciOLiYjg4OGDUqFHo27dvvdf5yiuvAACWLVuG\noqIiKBQKeHl5ae4T/SReXl5ISUnBtGnT4OTkhNDQULz77rv4+uuvoVKp0K9fP/Tv318zv7OzM7y9\nvTF79myo1WqsWrVK6/XatWunGfivPhrqk08+gVzO//4kHe9nQc+0iIgIODo6YuLEicYuheipxm4o\nIiLSiWFBREQ6sRuKiIh04p4FERHpxLAgIiKdGBZERKQTw4KIiHRiWBARkU7/D5tZu9/C/xMFAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11030b128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11030b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([sk_mem,custom_mem])\n",
    "plt.title(\"Comparing Memory \")\n",
    "plt.xlabel('Implementation ')\n",
    "plt.ylabel('Memory Usage (mb) ')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It looks like both implementations use similar amounts of memory, with SKL using a wider range. But there really isn't a clearly superior implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
