{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Five: Evaluation and Multi-Layer Perceptron\n",
    "## Rupal Sanghavi, Omar Roa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset represents the responses from students and their friends(ages 15-30, henceforth stated as \"young people\") of a Statistics class from the Faculty of Social and Economic Sciences at The Comenius University in Bratislava, Slovakia. Their survey was a mix of various topics.\n",
    "\n",
    "* Music preferences (19 items)\n",
    "* Movie preferences (12 items)\n",
    "* Hobbies & interests (32 items)\n",
    "* Phobias (10 items)\n",
    "* Health habits (3 items)\n",
    "* Personality traits, views on life, & opinions (57 items)\n",
    "* Spending habits (7 items)\n",
    "* Demographics (10 items)\n",
    "\n",
    "The dataset can be found here. https://www.kaggle.com/miroslavsabo/young-people-survey\n",
    "\n",
    "Our target is to predict how likely a young person would have an interest in PC Software and Hardware. According to Time Magazine (http://time.com/4433964/teens-social-media-advertising/), \"YouTube has become so saturated with popular vloggers that marketers are now turning to so-called \"micro-influencers\" with smaller but more devoted followings, while agencies are shifting their ad dollars from television to YouTube.\"\n",
    "\n",
    "What is a \"micro-influencer\"? \"A micro-influencer is usually Instafamous or a Youtube sensation with a relatively high social following who they have a great impact on.\" (https://www.bcsagency.com/news/step-aside-bloggers-its-time-for-micro-influencers-to-take-the-stage) According to Digiday (http://digiday.com/marketing/micro-influencers/), if a content creator with a large audience promotes a product, there is a chance that only a small subset of their audience is interested. A \"micro-influencer\" would likely have an audience that we mostly interested in a product placement by their trusted \"micro-influencer\".\n",
    "\n",
    "PC Software and Hardware is the classifier that we chose for this project, but there are various other interests in our dataset (Socializing, Dancing, Art) that could be predicted. The point is to gauge interest in a particular topic, hire a \"micro-influencer\" to generate content for that topic, and include product placement.\n",
    "\n",
    "As for how well this should perform? We weren't able to find many articles talking specifically about an algorithm to predict sales trends, but the market is certainly interested. \n",
    "\n",
    "* https://www.emarketer.com/Article/Marketers-Turn-Algorithms-Improve-Attribution/1014463\n",
    "* https://martechtoday.com/algorithms-advertising-7-steps-introducing-ai-marketing-195037\n",
    "* https://hbr.org/2015/06/the-perils-of-algorithm-based-marketing\n",
    "\n",
    "We would at a minimum like to perform as well as SKLearn. At best we would like to perform better based on our scoring function (mentioned below), meaning consistently get lower scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "%load_ext memory_profiler\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.special import expit\n",
    "import time\n",
    "import math\n",
    "from memory_profiler import memory_usage\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "target_classifier = 'PC'\n",
    "df = pd.read_csv('responses.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove rows whose target classfier value is NaN\n",
    "df_cleaned_classifier = df[np.isfinite(df[target_classifier])]\n",
    "# change NaN number values to the mean\n",
    "df_imputed = df_cleaned_classifier.fillna(df.mean())\n",
    "# get categorical features\n",
    "object_features = list(df_cleaned_classifier.select_dtypes(include=['object']).columns)\n",
    "# one hot encode categorical features\n",
    "one_hot_df = pd.concat([pd.get_dummies(df_imputed[col],prefix=col) for col in object_features], axis=1)\n",
    "# drop object features from imputed dataframe\n",
    "df_imputed_dropped = df_imputed.drop(object_features, 1)\n",
    "frames = [df_imputed_dropped, one_hot_df]\n",
    "# concatenate both frames by columns\n",
    "df_fixed = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_classifier.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1004, 173)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fixed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset (1010 rows and 150 columns) was mostly ordinal data as numbers (preferences ranked 1-5) . We also had some ordinal data as strings. \n",
    "\n",
    "e.g.\n",
    "How much time do you spend online?: No time at all - Less than an hour a day - Few hours a day - Most of the day\n",
    "\n",
    "We first removed any rows which contained NaN values for our target classifer, Shopping centres. Afterwards we imputed mean values for any NaN values in other features. We decided to impute due to the fact that there were not many NaN values in our features compared to the size of our data set. (At most was 20 for a feature, as shown above). We then one-hot encoded any string object, which created extra features.\n",
    "\n",
    "We are left with numerical values for our features and a size of 1007 x 172"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics To Evaluate Algorithm's Generalization Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(get_confusion_costTot, greater_is_better=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Research on Cost Matrix\n",
    "# http://www.ibm.com/support/knowledgecenter/SSEPGG_11.1.0/com.ibm.im.model.doc/c_cost_matrix.html\n",
    "\n",
    "cost_matrix = np.matrix([[0,1,2,3,4],\n",
    "[1,0,1,2,3],\n",
    "[3,1,0,1,2],\n",
    "[5,3,1,0,1],\n",
    "[7,5,2,1,0]])\n",
    "\n",
    "def get_confusion_costTot(confusion_matrix, cost_matrix):\n",
    "    score = np.sum(confusion_matrix*cost_matrix)\n",
    "    return score\n",
    "\n",
    "confusion_scorer = make_scorer(get_confusion_costTot, greater_is_better=False)\n",
    "confusion_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a cost matrix with advice from IBM's Knowledge Center. We heavily weighted having a false negative due to wasting money on someone who likely would not have interest in the topic and therefore not engage with the micro-influencer. A false positive carries a higher weight than most but is still not the most severe because the money spent on a micro-influencer is still not not wasted due to their more niche topics capturing audiences.\n",
    "The elements closer to a false negative are weighed heavier than the rest of the elements, which carry a weight of 1*d where d is the distance from the diagonal. We thought values with less confusion should carry less weight.\n",
    "We then multiply each element in our confusion matrix by the corresponding element in the cost matrix. This means that correct predictions will have no weight, but wrong predictions will carry some weight as discussed above.\n",
    "Finally, we sum the elements of the new matrix, and use that score as a way to determine performance. The lower the score, the less wrong predictions were made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if target_classifier in df_fixed:\n",
    "    y = df_fixed[target_classifier].values # get the label we want\n",
    "    del df_fixed[target_classifier] # get rid of the class label\n",
    "    X = df_fixed.values # use everything else to predict!\n",
    "\n",
    "X = X/5\n",
    "num_folds = 10\n",
    "\n",
    "cv_object = StratifiedKFold(n_splits= num_folds, random_state=None, shuffle=True)\n",
    "cv_object.split(X,y)\n",
    "\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using Stratified K Fold as our cross-validation object. Scikit's page states \"each set contains approximately the same percentage of samples of each target class as the complete set.\"(http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) This is important as we want to represent the dataset as accurately as possible. Kfolds also includes all our data over the course of the folds, so we know that all our data is being used at some point.\n",
    "\n",
    "We did not split our data into validation/train/test sets due to the fact that our data sample size is small (just over 1000 samples). We kept our data set split into training and test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Implementation of Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example adapted from https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "# Original Author: Sebastian Raschka\n",
    "# This is the optional book we use in the course, excellent intuitions and straightforward programming examples\n",
    "# please note, however, that this code has been manipulated to reflect our assumptions and notation.\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# start with a simple base classifier, which can't be fit or predicted\n",
    "# it only has internal classes to be used by classes that will subclass it\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None, nonlinearity = \"sigmoid\"):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.params = {}\n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "            \n",
    "        return onehot\n",
    "    \n",
    "    @staticmethod\n",
    "    def _relu(Z):\n",
    "        return np.maximum(0,Z.copy())\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        if(self.nonlinearity == \"sigmoid\"):\n",
    "            init_bound = np.sqrt(2. / (self.n_hidden + self.n_features_ + 1))\n",
    "            W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_ + 1))\n",
    "\n",
    "            init_bound = np.sqrt(2. / (self.n_output_ + self.n_hidden + 1))\n",
    "            W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden + 1))\n",
    "            \n",
    "        elif(self.nonlinearity == \"linear\"):\n",
    "            init_bound = np.sqrt(6. / (self.n_hidden + self.n_features_ + 1))\n",
    "            W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_ + 1))\n",
    "\n",
    "            init_bound = np.sqrt(6. / (self.n_output_ + self.n_hidden + 1))\n",
    "            W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden + 1))\n",
    "            \n",
    "        else:\n",
    "            init_bound = np.sqrt(6. / (self.n_hidden + self.n_features_ + 1))\n",
    "            W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_ + 1))\n",
    "\n",
    "            init_bound = np.sqrt(2. / (self.n_output_ + self.n_hidden + 1))\n",
    "            W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden + 1))\n",
    "            \n",
    "        return W1, W2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
    "        # 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_/2.0) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2))\n",
    "    \n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = np.mean((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _feedforward(self, X, W1, W2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        \"\"\"\n",
    "        A1 = self._add_bias_unit(X, how='column')\n",
    "        Z1 = W1 @ A1.T\n",
    "        if(self.nonlinearity == \"sigmoid\"):\n",
    "            A2 = self._sigmoid(Z1)\n",
    "            A2 = self._add_bias_unit(A2, how='row')\n",
    "            Z2 = W2 @ A2\n",
    "            A3 = self._sigmoid(Z2)\n",
    "        elif(self.nonlinearity == \"linear\"):\n",
    "            A2 = Z1\n",
    "            A2 = self._add_bias_unit(A2, how='row')\n",
    "            Z2 = W2 @ A2\n",
    "            A3 = Z2\n",
    "        else: #relu\n",
    "            # A1->W1->ReLu->A2->W2->Sigmoid\n",
    "            A1 = self._add_bias_unit(X, how='column')\n",
    "            Z1 = W1 @ A1.T\n",
    "            A2 = self._relu(Z1)\n",
    "            A2 = self._add_bias_unit(A2, how='row')\n",
    "            Z2 = W2 @ A2\n",
    "            A3 = self._sigmoid(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        if(self.nonlinearity == \"sigmoid\"):\n",
    "            sigma3 = -2*(Y_enc-A3)*A3*(1-A3)\n",
    "            sigma2 = (W2.T @ sigma3)*A2*(1-A2)\n",
    "        elif(self.nonlinearity == \"linear\"):\n",
    "            sigma3 = -2*(Y_enc-A3)\n",
    "            sigma2 = (W2.T @ sigma3)\n",
    "        else: #relu\n",
    "            sigma3 = (A3-Y_enc) \n",
    "            # sigma3[Z2<=0] = 0 # can change to be relu back prop on this layer too!\n",
    "\n",
    "            sigma2 = (W2.T @ sigma3) \n",
    "            Z1_with_bias = self._add_bias_unit(Z1,how='row')\n",
    "            sigma2[Z1_with_bias<=0] = 0\n",
    "            # relu derivative only zeros out certain values! easy!\n",
    "\n",
    "            \n",
    "            \n",
    "        grad1 = sigma2[1:,:] @ A1\n",
    "        grad2 = sigma3 @ A2.T\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += W1[:, 1:] * self.l2_C\n",
    "        grad2[:, 1:] += W2[:, 1:] * self.l2_C\n",
    "\n",
    "        return grad1, grad2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred\n",
    "    def get_params(self,deep=False):\n",
    "        return dict(n_hidden=self.n_hidden, C=self.l2_C, nonlinearity=self.nonlinearity)\n",
    "\n",
    "    def set_params(self,**kwds):\n",
    "        print(kwds)\n",
    "        self.n_hidden = kwds['n_hidden']\n",
    "        self.C = kwds['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# just start with the vectorized version and minibatch\n",
    "class TLPMiniBatch(TwoLayerPerceptronBase):\n",
    "    def __init__(self, alpha=0.0, decrease_const=0.0, shuffle=True, \n",
    "                 minibatches=1, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        delta_W1_prev = np.zeros(self.W1.shape)\n",
    "        delta_W2_prev = np.zeros(self.W2.shape)\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            self.eta /= (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       self.W1,\n",
    "                                                       self.W2)\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],self.W1,self.W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, \n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=self.W1,W2=self.W2)\n",
    "\n",
    "                delta_W1, delta_W2 = self.eta * grad1, self.eta * grad2\n",
    "                self.W1 -= (delta_W1 + (self.alpha * delta_W1_prev))\n",
    "                self.W2 -= (delta_W2 + (self.alpha * delta_W2_prev))\n",
    "                delta_W1_prev, delta_W2_prev = delta_W1, delta_W2\n",
    "\n",
    "            self.cost_.append(mini_cost)\n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            \n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to implement the new style of objective function, \n",
    "# we just need to update the final layer calculation of the gradient\n",
    "class TLPMiniBatchCrossEntropy(TLPMiniBatch):\n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A3)+(1-Y_enc)*np.log(1-A3))))\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        sigma3 = (A3-Y_enc) # <- this is only line that changed\n",
    "        if(self.nonlinearity == \"sigmoid\"):\n",
    "            sigma2 = (W2.T @ sigma3)*A2*(1-A2)\n",
    "            grad1 = sigma2[1:,:] @ A1\n",
    "            grad2 = sigma3 @ A2.T\n",
    "        else:\n",
    "            sigma2 = (W2.T @ sigma3)\n",
    "            grad1 = sigma2[1:,:] @ A1\n",
    "            grad2 = sigma3\n",
    "        #grad1 = sigma2[1:,:] @ A1\n",
    "        #grad2 = sigma3 @ A2.T\n",
    "        grad2 = sigma3 @ A2.T\n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += W1[:, 1:] * self.l2_C\n",
    "        grad2[:, 1:] += W2[:, 1:] * self.l2_C\n",
    "\n",
    "        return grad1, grad2\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class TLPDropout(TLPMiniBatchCrossEntropy):\n",
    "    def __init__(self, dropout=True, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.dropout = dropout\n",
    "\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    def fit(self, X, y, print_progress=0, XY_test=None):\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        delta_W1_prev = np.zeros(self.W1.shape)\n",
    "        delta_W2_prev = np.zeros(self.W2.shape)\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        if XY_test is not None:\n",
    "            X_test = XY_test[0].copy()\n",
    "            y_test = XY_test[1].copy()\n",
    "            self.val_score_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            self.eta /= (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            \n",
    "            # adding dropout neurons\n",
    "            W1 = self.W1.copy()\n",
    "            W2 = self.W2.copy()\n",
    "            \n",
    "            if self.dropout:\n",
    "                # be sure to select the other half of the neurons each epoch\n",
    "                if True :#i%2 == 0:\n",
    "                    # randomly select half of the neurons\n",
    "                    idx_dropout = np.random.permutation(W1.shape[0])\n",
    "                    idx_other_half = idx_dropout[:int(W1.shape[0]/2)]\n",
    "                    idx_dropout = idx_dropout[int(W1.shape[0]/2):] #drop half\n",
    "                else:\n",
    "                    # select the other half\n",
    "                    idx_dropout = idx_other_half\n",
    "                    \n",
    "                idx_dropout = np.sort(idx_dropout)\n",
    "                idx_W2_withbias = np.hstack(([0],(idx_dropout+1)))\n",
    "                W1 = W1[idx_dropout,:]# get rid of rows\n",
    "                W2 = W2[:,idx_W2_withbias]# get rid of extra columns\n",
    "                delta_W1_prev_dropout = delta_W1_prev[idx_dropout,:]\n",
    "                delta_W2_prev_dropout = delta_W2_prev[:,idx_W2_withbias]\n",
    "            else:\n",
    "                delta_W1_prev_dropout = delta_W1_prev\n",
    "                delta_W2_prev_dropout = delta_W2_prev\n",
    "                \n",
    "            \n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       W1,\n",
    "                                                       W2)\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],W1,W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2,\n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=W1,W2=W2)\n",
    "\n",
    "                delta_W1, delta_W2 = self.eta * grad1, self.eta * grad2\n",
    "                W1 -= (delta_W1 + (self.alpha * delta_W1_prev_dropout))\n",
    "                W2 -= (delta_W2 + (self.alpha * delta_W2_prev_dropout))\n",
    "                delta_W1_prev_dropout, delta_W2_prev_dropout = delta_W1, delta_W2\n",
    "\n",
    "            if self.dropout:\n",
    "                # now append the learned weights back into the original matrices\n",
    "                self.W1[idx_dropout,:] = W1\n",
    "                self.W2[:,idx_W2_withbias] = W2\n",
    "                delta_W1_prev[idx_dropout,:] = delta_W1_prev_dropout\n",
    "                delta_W2_prev[:,idx_W2_withbias] = delta_W2_prev_dropout\n",
    "            else:\n",
    "                # don't eliminate any neurons\n",
    "                self.W1 = W1\n",
    "                self.W2 = W2\n",
    "                delta_W1_prev = delta_W1_prev_dropout\n",
    "                delta_W2_prev = delta_W2_prev_dropout\n",
    "                \n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            self.cost_.append(mini_cost) # only uses dropped samples, so more noise\n",
    "            if XY_test is not None:\n",
    "                self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TLPGaussianInitialQuad(TLPMiniBatch):             \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with smal l random numbers.\"\"\"\n",
    "        W1 = np.random.randn(self.n_hidden, self.n_features_ + 1)\n",
    "        W1[:,1:] = W1[:,1:]/np.sqrt(self.n_features_+1) # don't saturate the neuron\n",
    "        \n",
    "        W2 = np.random.randn(self.n_output_, self.n_hidden + 1)\n",
    "        W2[:,1:] = W2[:,1:]/np.sqrt(self.n_hidden+1) # don't saturate the neuron\n",
    "        return W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TLPGaussianInitial(TLPMiniBatchCrossEntropy):             \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        W1 = np.random.randn(self.n_hidden, self.n_features_ + 1)\n",
    "        W1[:,1:] = W1[:,1:]/np.sqrt(self.n_features_+1) # don't saturate the neuron\n",
    "        \n",
    "        W2 = np.random.randn(self.n_output_, self.n_hidden + 1)\n",
    "        W2[:,1:] = W2[:,1:]/np.sqrt(self.n_hidden+1) # don't saturate the neuron\n",
    "        return W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals = {'n_hidden':50, \n",
    "         'C':1e-2, 'epochs':75, 'eta':0.001, \n",
    "         'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "         'shuffle':True,'random_state':1, 'dropout':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TLPReLu(TLPDropout):\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        # suggested relu/sigmoid bounds\n",
    "        # Glorot, Xavier, Antoine Bordes, and Yoshua Bengio. \n",
    "        #   \"Deep Sparse Rectifier Neural Networks.\"\n",
    "        init_bound = np.sqrt(6. / (self.n_hidden + self.n_features_ + 1))\n",
    "        W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_ + 1))\n",
    "\n",
    "        init_bound = np.sqrt(2. / (self.n_output_ + self.n_hidden + 1))\n",
    "        W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden + 1))\n",
    "        return W1, W2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _relu(Z):\n",
    "        return np.maximum(0,Z.copy())\n",
    "        \n",
    "    def _feedforward(self, X, W1, W2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        \"\"\"\n",
    "        # A1->W1->ReLu->A2->W2->Sigmoid\n",
    "        A1 = self._add_bias_unit(X, how='column')\n",
    "        Z1 = W1 @ A1.T\n",
    "        A2 = self._relu(Z1)\n",
    "        A2 = self._add_bias_unit(A2, how='row')\n",
    "        Z2 = W2 @ A2\n",
    "        A3 = self._sigmoid(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        sigma3 = (A3-Y_enc) \n",
    "        # sigma3[Z2<=0] = 0 # can change to be relu back prop on this layer too!\n",
    "        \n",
    "        sigma2 = (W2.T @ sigma3) \n",
    "        Z1_with_bias = self._add_bias_unit(Z1,how='row')\n",
    "        sigma2[Z1_with_bias<=0] = 0\n",
    "        # relu derivative only zeros out certain values! easy!\n",
    "        \n",
    "        grad1 = sigma2[1:,:] @ A1\n",
    "        grad2 = sigma3 @ A2.T\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += (W1[:, 1:] * self.l2_C)\n",
    "        grad2[:, 1:] += (W2[:, 1:] * self.l2_C)\n",
    "\n",
    "        return grad1, grad2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 s, sys: 296 ms, total: 15.3 s\n",
      "Wall time: 3.91 s\n",
      "confusion matrix\n",
      " [[ 0 10  3  0  1]\n",
      " [ 0 11  7  0  3]\n",
      " [ 0  7 11  0  7]\n",
      " [ 0  5  7  0  9]\n",
      " [ 0  2  5  0 14]]\n",
      "Weighted Confusion Matrix Score:  986\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.7 s, sys: 273 ms, total: 15 s\n",
      "Wall time: 3.79 s\n",
      "confusion matrix\n",
      " [[ 0  7  7  0  0]\n",
      " [ 0  8  7  0  6]\n",
      " [ 0  7  5  0 13]\n",
      " [ 0  1  5  0 15]\n",
      " [ 0  3  4  0 14]]\n",
      "Weighted Confusion Matrix Score:  1098\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 359 ms, total: 15.5 s\n",
      "Wall time: 3.95 s\n",
      "confusion matrix\n",
      " [[ 0  5  6  0  3]\n",
      " [ 0  6 10  0  5]\n",
      " [ 0  5 10  0 10]\n",
      " [ 0  2  6  0 13]\n",
      " [ 0  0  2  0 19]]\n",
      "Weighted Confusion Matrix Score:  1114\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.1 s, sys: 299 ms, total: 15.4 s\n",
      "Wall time: 3.89 s\n",
      "confusion matrix\n",
      " [[ 0  5  7  0  2]\n",
      " [ 0  8 12  0  1]\n",
      " [ 0  5 14  0  6]\n",
      " [ 0  4 10  0  7]\n",
      " [ 0  1 12  0  8]]\n",
      "Weighted Confusion Matrix Score:  906\n",
      "---------------------------------\n",
      "\n",
      "quadratic\n",
      "sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 51/75"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-34b0137c49c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0;31m#%time nn_long_sigmoid.fit(X_train, y_train, print_progress=1, XY_test=(X_test,y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time nn_long_sigmoid.fit(X_train, y_train, print_progress=1)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_long_sigmoid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get test set precitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6af9468bfcd2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, print_progress)\u001b[0m\n\u001b[1;32m     50\u001b[0m                                                        self.W2)\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_enc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0mmini_cost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this appends cost of mini-batch only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c38322146d7a>\u001b[0m in \u001b[0;36m_cost\u001b[0;34m(self, A3, Y_enc, W1, W2)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;34m'''Get the objective function value'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_enc\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mA3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mL2_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_L2_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mL2_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c38322146d7a>\u001b[0m in \u001b[0;36m_L2_reg\u001b[0;34m(lambda_, W1, W2)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;34m\"\"\"Compute L2-regularization cost\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# only compute for non-bias terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_enc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2884\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2885\u001b[0;31m                           out=out, keepdims=keepdims)\n\u001b[0m\u001b[1;32m   2886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with np.errstate(all='ignore'):\n",
    "\n",
    "    nonlinearities = [\"sigmoid\",\"linear\"]\n",
    "    costs = ['quadratic','cross']\n",
    "    \n",
    "    custom_performances = []\n",
    "    lowest_score = 10000\n",
    "    best_cost = \"\"\n",
    "    best_nonlin = \"\"\n",
    "for cost in costs:\n",
    "    for nonlinearity in nonlinearities:\n",
    "\n",
    "        vals = {'n_hidden':50, \n",
    "                     'C':1e-2, 'epochs':75, 'eta':0.001, \n",
    "                     'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "                     'shuffle':True,'random_state':1, \n",
    "                       'nonlinearity': nonlinearity}\n",
    "        for train_indices, test_indices in cv_object.split(X,y): \n",
    "                    print(\"---------------------------------\")\n",
    "                    print(\"\")\n",
    "                    print(cost)\n",
    "                    print(nonlinearity)\n",
    "                    # I will create new variables here so that it is more obvious what \n",
    "                    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "                    # but it makes this code less readable)\n",
    "                    X_train = (X[train_indices])\n",
    "                    y_train = y[train_indices]\n",
    "\n",
    "                    X_test = (X[test_indices])\n",
    "                    y_test = y[test_indices]\n",
    "                    \n",
    "                    if(cost == \"quadratic\"):\n",
    "                        nn_long_sigmoid = TLPGaussianInitialQuad(**vals)\n",
    "                    else:\n",
    "                        print(\"in\")\n",
    "                        nn_long_sigmoid = TLPGaussianInitial(**vals)\n",
    "\n",
    "                    #%time nn_long_sigmoid.fit(X_train, y_train, print_progress=1, XY_test=(X_test,y_test))\n",
    "                    %time nn_long_sigmoid.fit(X_train, y_train, print_progress=1)\n",
    "                    y_hat = nn_long_sigmoid.predict(X_test) # get test set precitions\n",
    "\n",
    "                    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "                    acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "            #         lr_clf_accuracies.append(acc)\n",
    "            #         cost_accuracies.append([acc])\n",
    "\n",
    "                    conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "        #             print(vals)\n",
    "#                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "#                     plt.show()\n",
    "                    print(\"confusion matrix\\n\",conf)\n",
    "                    score = get_confusion_costTot(conf, cost_matrix)\n",
    "                    print(\"Weighted Confusion Matrix Score: \", score)\n",
    "                    custom_performances.append(score)\n",
    "                    if(score < lowest_score): \n",
    "                        lowest_score=score\n",
    "                        best_cost=cost\n",
    "                        best_nonlin=nonlinearity\n",
    "\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "print(\"Best Score: \",lowest_score)               \n",
    "print(\"Best cost: \",best_cost)\n",
    "print(\"Best Non-Linearity: \",best_nonlin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_neurons = np.linspace(50, 200)\n",
    "hidden_neurons.sort()\n",
    "\n",
    "costs = np.logspace(-3,1)\n",
    "costs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'n_hidden': 50.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'n_hidden': 50.0}\n",
      "{'C': 0.001, 'n_hidden': 50.0}\n",
      "{'C': 0.001, 'n_hidden': 50.0}\n",
      "{'C': 0.001, 'n_hidden': 50.0}\n",
      "{'C': 0.001, 'n_hidden': 50.0}\n",
      "{'C': 0.001, 'n_hidden': 50.0}\n",
      "{'C': 0.001, 'n_hidden': 50.0}\n",
      "{'C': 0.001, 'n_hidden': 50.0}\n",
      "{'C': 0.001, 'n_hidden': 50.0}\n",
      "{'C': 0.001, 'n_hidden': 53.061224489795919}\n",
      "{'C': 0.001, 'n_hidden': 53.061224489795919}\n",
      "{'C': 0.001, 'n_hidden': 53.061224489795919}\n",
      "{'C': 0.001, 'n_hidden': 53.061224489795919}\n",
      "{'C': 0.001, 'n_hidden': 53.061224489795919}\n",
      "{'C': 0.001, 'n_hidden': 53.061224489795919}\n",
      "{'C': 0.001, 'n_hidden': 53.061224489795919}\n",
      "{'C': 0.001, 'n_hidden': 53.061224489795919}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-eea86d97dc79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mparam_grid_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_hidden'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhidden_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcosts\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgscv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcv_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn_long_sigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mparam_grid_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mconfusion_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgscv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6af9468bfcd2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, print_progress)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, \n\u001b[1;32m     57\u001b[0m                                                   \u001b[0mY_enc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_enc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                                                   W1=self.W1,W2=self.W2)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mdelta_W1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_W2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c38322146d7a>\u001b[0m in \u001b[0;36m_get_gradient\u001b[0;34m(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonlinearity\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0msigma3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_enc\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mA3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mA3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mA3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0msigma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0msigma3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mA2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mA2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonlinearity\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0msigma3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_enc\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mA3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with np.errstate(all='ignore'):\n",
    "    param_grid_input = {'n_hidden': hidden_neurons, 'C': costs}\n",
    "    gscv = GridSearchCV(cv= cv_object, estimator=nn_long_sigmoid, param_grid= param_grid_input, scoring= confusion_scorer,refit=False)\n",
    "    gscv.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using our scoring method using mentioned earlier to determine the best values for our hyperameters C (costs), and n_hidden (number of neurons in the hidden layer). With GridSearch, we will exhausitvely test our hyperamters and see which gives us our best score (mentioned under Evaluation above). We decided to use only two hyper parameters because our laptops were taking large amounts of time once we included three hyperparamters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b28f46b0159a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgscv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mbest_params_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbest_params_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cv_results_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# FIXME NotFittedError_ --> NotFittedError in 0.19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_NotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "best_params=gscv.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found our best hyperparameters. Two hyperparameters still took a long time, it took Friday 1:00 am to Sunday late morning for GridSearch to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_neurons = np.linspace(50, 200, num=10)\n",
    "hidden_neurons.sort()\n",
    "\n",
    "costs = np.logspace(-3,1,num=10)\n",
    "costs.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a subset of our hyperparameters as it took too long to perform all the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neuron_perf = [[] for i in range(len(hidden_neurons))]\n",
    "i = 0\n",
    "\n",
    "for neurons in hidden_neurons:\n",
    "\n",
    "        vals = {'n_hidden':neurons, \n",
    "                     'C':1e-2, 'epochs':75, 'eta':0.001, \n",
    "                     'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "                     'shuffle':True,'random_state':1, \n",
    "                       'nonlinearity': \"sigmoid\"}\n",
    "        for train_indices, test_indices in cv_object.split(X,y): \n",
    "                    print(\"---------------------------------\")\n",
    "\n",
    "                    X_train = (X[train_indices])\n",
    "                    y_train = y[train_indices]\n",
    "\n",
    "                    X_test = (X[test_indices])\n",
    "                    y_test = y[test_indices]\n",
    "                    \n",
    "                    nn_long_sigmoid = TLPGaussianInitial(**vals)\n",
    "\n",
    "                    #%time nn_long_sigmoid.fit(X_train, y_train, print_progress=1, XY_test=(X_test,y_test))\n",
    "                    %time nn_long_sigmoid.fit(X_train, y_train, print_progress=1)\n",
    "                    y_hat = nn_long_sigmoid.predict(X_test) # get test set precitions\n",
    "\n",
    "                    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "                    acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "            #         lr_clf_accuracies.append(acc)\n",
    "            #         cost_accuracies.append([acc])\n",
    "\n",
    "                    conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "        #             print(vals)\n",
    "#                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "#                     plt.show()\n",
    "                    print(\"confusion matrix\\n\",conf)\n",
    "                    score = get_confusion_costTot(conf, cost_matrix)\n",
    "                    print(\"Weighted Confusion Matrix Score: \", score)\n",
    "                    neuron_perf[i].append(score)\n",
    "        i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# neuron_perf = [int(i) for i in neuron_perf] \n",
    "plt.boxplot(neuron_perf)\n",
    "plt.title(\"Varying Hyper-Parameter: Number of Neurons\")\n",
    "plt.xlabel('Number of neurons')\n",
    "plt.ylabel('Generalization Performance')\n",
    "plt.xticks([1,2,3,4,5,6,7,8,9,10],hidden_neurons, rotation=90)\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that the number of neurons that gave us our best performance score is 150, which is different than what GridSearch gave us (50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost_perf = [[] for i in range(len(costs))]\n",
    "i = 0\n",
    "\n",
    "for cost in costs:\n",
    "\n",
    "        vals = {'n_hidden':neurons, \n",
    "                     'C':1e-2, 'epochs':15, 'eta':0.001, \n",
    "                     'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "                     'shuffle':True,'random_state':1, \n",
    "                       'nonlinearity': \"sigmoid\"}\n",
    "        for train_indices, test_indices in cv_object.split(X,y): \n",
    "                    print(\"---------------------------------\")\n",
    "\n",
    "                    X_train = (X[train_indices])\n",
    "                    y_train = y[train_indices]\n",
    "\n",
    "                    X_test = (X[test_indices])\n",
    "                    y_test = y[test_indices]\n",
    "                    \n",
    "                    nn_long_sigmoid = TLPGaussianInitial(**vals)\n",
    "\n",
    "                    #%time nn_long_sigmoid.fit(X_train, y_train, print_progress=1, XY_test=(X_test,y_test))\n",
    "                    %time nn_long_sigmoid.fit(X_train, y_train, print_progress=1)\n",
    "                    y_hat = nn_long_sigmoid.predict(X_test) # get test set precitions\n",
    "\n",
    "                    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "                    acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "            #         lr_clf_accuracies.append(acc)\n",
    "            #         cost_accuracies.append([acc])\n",
    "\n",
    "                    conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "        #             print(vals)\n",
    "#                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "#                     plt.show()\n",
    "                    print(\"confusion matrix\\n\",conf)\n",
    "                    score = get_confusion_costTot(conf, cost_matrix)\n",
    "                    print(\"Weighted Confusion Matrix Score: \", score)\n",
    "                    cost_perf[i].append(score)\n",
    "        i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.boxplot(cost_perf)\n",
    "plt.title(\"Varying Hyper-Parameter: Regularization Parameter\")\n",
    "plt.xlabel('Regularization Parameter')\n",
    "plt.ylabel('Generalization Performance')\n",
    "plt.xticks([1,2,3,4,5,6,7,8,9,10],costs, rotation=90)\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We noticed that the cost that gave us our best performance score is .002, which is different than what GridSearch gave us (.001)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing our MLP Implementation with that of Scikit Learn  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2    3    4    5    6    7    8    9   10   11   12   14   15\n",
      "   16   17   19   20   21   22   23   24   25   26   27   28   29   31   32\n",
      "   33   34   35   36   37   38   39   41   42   43   44   45   46   47   48\n",
      "   49   50   51   52   54   55   56   57   58   59   60   61   62   64   65\n",
      "   66   67   68   69   70   71   72   73   74   76   78   79   80   81   82\n",
      "   83   84   85   86   87   88   89   90   92   93   94   95   96   97   98\n",
      "   99  100  101  102  103  104  105  106  107  108  109  110  111  112  113\n",
      "  114  115  116  117  118  119  120  121  122  123  124  125  126  127  130\n",
      "  131  132  133  134  135  136  137  138  139  140  141  142  143  144  145\n",
      "  146  147  148  149  150  151  152  153  154  157  158  159  160  161  162\n",
      "  163  164  165  166  167  168  169  171  172  173  175  177  178  179  180\n",
      "  181  182  183  184  185  186  187  188  189  190  191  194  195  196  198\n",
      "  199  200  201  202  203  204  205  206  207  208  209  210  211  212  213\n",
      "  215  216  217  218  219  220  221  222  223  224  225  226  227  228  229\n",
      "  230  231  232  233  234  235  236  237  238  240  241  242  243  244  245\n",
      "  246  247  248  249  250  251  252  253  256  257  258  259  260  261  262\n",
      "  263  265  266  267  268  269  270  271  272  273  274  275  276  277  278\n",
      "  279  280  281  282  283  285  287  288  289  291  292  293  294  295  296\n",
      "  297  299  301  302  303  304  305  306  308  309  310  312  313  314  315\n",
      "  316  318  319  320  321  322  323  324  325  327  329  330  331  332  334\n",
      "  335  336  337  338  339  340  341  342  343  344  345  346  347  348  349\n",
      "  350  352  353  354  355  356  357  358  359  360  361  362  363  365  366\n",
      "  367  368  370  371  372  373  374  375  376  377  378  379  380  381  382\n",
      "  383  384  385  386  387  389  390  391  392  393  394  395  396  397  398\n",
      "  399  400  401  402  403  404  405  406  407  408  410  411  412  413  414\n",
      "  416  417  419  420  422  423  424  425  426  428  429  431  432  433  434\n",
      "  435  436  437  438  439  440  441  442  443  444  445  446  447  448  449\n",
      "  450  451  454  455  456  457  458  459  460  461  462  463  464  466  467\n",
      "  468  469  470  471  472  473  474  475  477  479  480  481  482  483  484\n",
      "  485  486  487  488  489  490  491  492  493  494  495  496  497  498  499\n",
      "  500  501  502  503  504  505  506  507  508  509  510  511  513  514  515\n",
      "  516  517  518  519  520  521  522  523  524  526  527  528  529  530  531\n",
      "  532  533  534  536  538  539  540  541  542  543  544  545  546  547  548\n",
      "  549  550  551  552  553  554  555  556  558  559  560  561  562  565  566\n",
      "  567  568  569  571  572  573  574  575  576  577  578  579  580  581  582\n",
      "  583  585  586  587  588  589  590  591  592  593  594  595  596  597  598\n",
      "  599  600  601  602  604  606  607  608  609  610  612  613  614  615  616\n",
      "  617  618  619  620  621  622  623  624  625  626  627  628  629  630  633\n",
      "  635  636  637  638  640  641  642  643  644  646  647  648  649  650  651\n",
      "  652  653  654  655  657  658  659  660  661  662  663  665  666  667  668\n",
      "  669  670  671  672  673  674  676  677  678  679  680  681  682  683  684\n",
      "  685  686  687  688  689  690  691  692  693  694  695  697  698  699  700\n",
      "  702  703  704  705  707  708  709  710  711  713  714  715  716  717  718\n",
      "  719  720  721  722  724  725  726  727  728  729  730  731  732  733  734\n",
      "  735  736  737  738  739  740  741  742  743  744  745  746  747  748  749\n",
      "  750  752  753  754  755  756  757  758  759  760  761  762  763  765  766\n",
      "  767  769  770  771  772  773  774  775  776  778  781  782  783  784  785\n",
      "  786  787  788  789  790  791  792  793  794  795  796  797  800  801  802\n",
      "  803  804  805  806  807  808  809  810  811  812  813  814  816  817  818\n",
      "  819  820  821  822  823  824  825  826  827  828  829  830  831  832  833\n",
      "  834  836  837  838  839  840  841  842  843  844  845  846  847  848  849\n",
      "  850  851  852  853  854  855  856  857  858  859  860  861  864  865  866\n",
      "  867  868  869  870  871  872  873  874  875  876  877  878  880  881  883\n",
      "  884  885  886  887  889  890  891  892  893  894  895  896  897  898  899\n",
      "  900  902  903  905  906  907  908  909  910  911  912  913  914  915  916\n",
      "  919  921  922  923  924  925  926  928  930  931  932  933  934  935  936\n",
      "  937  938  939  940  941  942  943  944  945  946  947  948  949  951  953\n",
      "  954  955  956  957  958  959  960  961  963  964  965  966  967  968  969\n",
      "  970  971  972  973  974  976  977  978  979  980  981  982  983  984  985\n",
      "  986  987  988  989  990  991  992  993  994  995  996  997  998  999 1000\n",
      " 1001 1002 1003]\n"
     ]
    }
   ],
   "source": [
    "print(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.32 s\n",
      "confusion matrix\n",
      " [[ 0  9  4  0  1]\n",
      " [ 0 14  5  0  2]\n",
      " [ 0  9 12  0  4]\n",
      " [ 0  6 12  0  3]\n",
      " [ 0  4  8  0  9]]\n",
      "Weighted Confusion Matrix Score:  866\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.245098039216\n",
      "confusion matrix\n",
      " [[ 0  0 14  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 21  0  0]]\n",
      "Weighted Confusion Matrix Score:  714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.16 s\n",
      "confusion matrix\n",
      " [[ 0 11  3  0  0]\n",
      " [ 0 12  3  1  5]\n",
      " [ 0  9  7  0  9]\n",
      " [ 0 11  5  0  5]\n",
      " [ 0  4  1  2 14]]\n",
      "Weighted Confusion Matrix Score:  987\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.245098039216\n",
      "confusion matrix\n",
      " [[ 0  0 14  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 21  0  0]]\n",
      "Weighted Confusion Matrix Score:  714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.59 s\n",
      "confusion matrix\n",
      " [[ 0 12  0  2  0]\n",
      " [ 0 20  0  1  0]\n",
      " [ 0 16  0  8  1]\n",
      " [ 0 11  0  2  8]\n",
      " [ 0  3  0  8 10]]\n",
      "Weighted Confusion Matrix Score:  929\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.245098039216\n",
      "confusion matrix\n",
      " [[ 0  0 14  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 21  0  0]]\n",
      "Weighted Confusion Matrix Score:  714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.2 s\n",
      "confusion matrix\n",
      " [[ 0  7  7  0  0]\n",
      " [ 0  9 12  0  0]\n",
      " [ 0  5 19  0  1]\n",
      " [ 0  1 19  0  1]\n",
      " [ 0  1 19  0  1]]\n",
      "Weighted Confusion Matrix Score:  738\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.245098039216\n",
      "confusion matrix\n",
      " [[ 0  0 14  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 21  0  0]]\n",
      "Weighted Confusion Matrix Score:  714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.94 s\n",
      "confusion matrix\n",
      " [[ 0 13  0  0  1]\n",
      " [ 0 20  0  1  0]\n",
      " [ 0 17  4  0  4]\n",
      " [ 0 11  3  0  7]\n",
      " [ 0  6  3  1 10]]\n",
      "Weighted Confusion Matrix Score:  889\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.247524752475\n",
      "confusion matrix\n",
      " [[ 0  1 13  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.9 s\n",
      "confusion matrix\n",
      " [[ 0  5  8  0  0]\n",
      " [ 0  7 14  0  0]\n",
      " [ 0  3 19  0  3]\n",
      " [ 0  2 14  0  5]\n",
      " [ 0  1  9  0 10]]\n",
      "Weighted Confusion Matrix Score:  844\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.25\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.49 s\n",
      "confusion matrix\n",
      " [[ 0  5  7  0  1]\n",
      " [ 0  8 11  0  2]\n",
      " [ 0 10 10  0  5]\n",
      " [ 0  4  7  1  9]\n",
      " [ 0  4  5  0 11]]\n",
      "Weighted Confusion Matrix Score:  927\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.25\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.31 s\n",
      "confusion matrix\n",
      " [[ 0 11  1  1  0]\n",
      " [ 0 11  2  2  6]\n",
      " [ 0  9  2  2 12]\n",
      " [ 0  2  0  4 14]\n",
      " [ 0  1  0  2 17]]\n",
      "Weighted Confusion Matrix Score:  1118\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.252525252525\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 21  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 20  0  0]\n",
      " [ 0  0 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.36 s\n",
      "confusion matrix\n",
      " [[ 0  1 11  0  1]\n",
      " [ 0  4 14  0  2]\n",
      " [ 0  0 20  0  5]\n",
      " [ 0  1 12  0  7]\n",
      " [ 0  1  7  0 12]]\n",
      "Weighted Confusion Matrix Score:  902\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.255102040816\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 20  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 20  0  0]\n",
      " [ 0  0 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.68 s\n",
      "confusion matrix\n",
      " [[ 0 11  0  0  2]\n",
      " [ 0  8  2  1  9]\n",
      " [ 0  5  9  0 11]\n",
      " [ 0  5  2  0 13]\n",
      " [ 0  1  1  0 18]]\n",
      "Weighted Confusion Matrix Score:  1113\n",
      "SCIKIT*****\n",
      "Validation Acc: 0.255102040816\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 20  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 20  0  0]\n",
      " [ 0  0 20  0  0]]\n",
      "Weighted Confusion Matrix Score:  686\n"
     ]
    }
   ],
   "source": [
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "vals = {'n_hidden':150, \n",
    "         'C':0.002, 'epochs':75, 'eta':0.001, \n",
    "         'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "         'shuffle':True,'random_state':1, \n",
    "           'nonlinearity': \"sigmoid\"}\n",
    "custom_performances = []\n",
    "custom_times = []\n",
    "custom_mem = []\n",
    "sk_performances = []\n",
    "sk_times = []\n",
    "sk_mem = []\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "            \n",
    "            # I will create new variables here so that it is more obvious what \n",
    "            # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "            # but it makes this code less readable)\n",
    "            X_train = (X[train_indices])\n",
    "            y_train = y[train_indices]\n",
    "\n",
    "            X_test = (X[test_indices])\n",
    "            y_test = y[test_indices]\n",
    "\n",
    "            nn_long_sigmoid = TLPGaussianInitial(**vals)\n",
    "           \n",
    "\n",
    "            #%time nn_long_sigmoid.fit(X_train, y_train, print_progress=1, XY_test=(X_test,y_test))\n",
    "            st = time.time()\n",
    "\n",
    "            mem = memory_usage((nn_long_sigmoid.fit,(X_train,y_train))) # train object\n",
    "            t = (time.time() -st)\n",
    "            custom_times.append(t)\n",
    "            custom_mem.append(mem[0])\n",
    "\n",
    "            %time nn_long_sigmoid.fit(X_train, y_train, print_progress=1)\n",
    "            y_hat = nn_long_sigmoid.predict(X_test) # get test set precitions\n",
    "\n",
    "            # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "            acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "    #         lr_clf_accuracies.append(acc)\n",
    "    #         cost_accuracies.append([acc])\n",
    "\n",
    "            conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "#             print(vals)\n",
    "#                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "#                     plt.show()\n",
    "            print(\"confusion matrix\\n\",conf)\n",
    "            score = get_confusion_costTot(conf, cost_matrix)\n",
    "            print(\"Weighted Confusion Matrix Score: \", score)\n",
    "            custom_performances.append(score)\n",
    "            \n",
    "            clf = MLPClassifier(hidden_layer_sizes=(50, ), \n",
    "                        activation='relu', # type of non-linearity, every layer\n",
    "                        solver='sgd', \n",
    "                        alpha=1e-4, # L2 penalty\n",
    "                        batch_size= 'auto', # min of 200, num_samples\n",
    "                        learning_rate='constant', # adapt learning? only for sgd\n",
    "                        learning_rate_init=0.1, # only SGD\n",
    "                        power_t=0.0,    # only SGD with inverse scaling of learning rate\n",
    "                        max_iter=75, # stopping criteria\n",
    "                        shuffle=True, \n",
    "                        random_state=1, \n",
    "                        tol=0, # for stopping\n",
    "                        verbose=False, \n",
    "                        warm_start=False, \n",
    "                        momentum=0.9, # only SGD\n",
    "                        nesterovs_momentum=False, # only SGD\n",
    "                        early_stopping=False, \n",
    "                        validation_fraction=0.0, # only if early_stop is true\n",
    "                        beta_1=0.9, # adam decay rate of moment\n",
    "                        beta_2=0.999, # adam decay rate of moment\n",
    "                        epsilon=1e-08) # adam numerical stabilizer\n",
    "            \n",
    "            print(\"SCIKIT*****\")\n",
    "            \n",
    "            st = time.time()\n",
    "\n",
    "            mem = memory_usage((clf.fit,(X_train,y_train))) # train object\n",
    "            t = (time.time() -st)\n",
    "            sk_times.append(t)\n",
    "            sk_mem.append(mem[0])\n",
    "#             %time clf.fit(X_train,y_train)\n",
    "            yhat2 = clf.predict(X_test)\n",
    "            print('Validation Acc:',accuracy_score(yhat2,y_test))\n",
    "            conf2 = mt.confusion_matrix(y_test,yhat2)\n",
    "                    #             print(vals)\n",
    "            #                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "            #                     plt.show()\n",
    "            print(\"confusion matrix\\n\",conf2)\n",
    "            score = get_confusion_costTot(conf2, cost_matrix)\n",
    "            print(\"Weighted Confusion Matrix Score: \", score)\n",
    "            sk_performances.append(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Implementations in terms of Generalization Performance, Computation Time, and Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[714, 714, 714, 714, 707, 700, 700, 693, 686, 686]\n",
      "[866, 987, 929, 738, 889, 844, 927, 1118, 902, 1113]\n"
     ]
    }
   ],
   "source": [
    "print(sk_performances)\n",
    "print(custom_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1930.1609516143799\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAFyCAYAAAAnENp+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMmJmZmaVcjJiZmZmlfr/Q1mmnW+0QfIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac69f2b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac69f2ba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([sk_performances,custom_performances])\n",
    "plt.title(\"Comparing Generalization Perfomances\")\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Generalization Performances')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()\n",
    "print((time.time() -st)*100)\n",
    "# ax = fig.add_subplot(111)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKL performed much better (lower scores) than our implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac69f2b9e8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAGHCAYAAAAOSQDRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac69f2b8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac69f2b9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([sk_times,custom_times])\n",
    "plt.title(\"Comparing Computation Times\")\n",
    "plt.xlabel('Implementation')\n",
    "plt.ylabel('Training Time (seconds) ')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKL also trains much faster than our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac6a000198>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGHCAYAAABrpPKuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac6a000160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac6a000198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([sk_mem,custom_mem])\n",
    "plt.title(\"Comparing Memory \")\n",
    "plt.xlabel('Implementation ')\n",
    "plt.ylabel('Memory Usage (mb) ')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It looks like both implementations use similar amounts of memory. There really isn't a clearly superior implementation for memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added support for the nonlinear activation: Rectified Linear Units in the base TwoLayerPerceptron class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.5 s\n",
      "confusion matrix\n",
      " [[ 4  7  0  3  0]\n",
      " [ 8  9  1  3  0]\n",
      " [ 1 13  2  7  2]\n",
      " [ 1  7  0 10  3]\n",
      " [ 0  4  1  8  8]]\n",
      "Weighted Confusion Matrix Score:  953\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.73 s\n",
      "confusion matrix\n",
      " [[ 0 10  1  1  2]\n",
      " [ 0 18  0  0  3]\n",
      " [ 0 15  1  0  9]\n",
      " [ 0 10  1  0 10]\n",
      " [ 0  5  0  0 16]]\n",
      "Weighted Confusion Matrix Score:  1037\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.69 s\n",
      "confusion matrix\n",
      " [[ 0 12  0  2  0]\n",
      " [ 0 14  0  7  0]\n",
      " [ 0  9  0 12  4]\n",
      " [ 0  6  0 10  5]\n",
      " [ 0  2  0 10  9]]\n",
      "Weighted Confusion Matrix Score:  981\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.77 s\n",
      "confusion matrix\n",
      " [[ 1 11  2  0  0]\n",
      " [ 1 14  4  0  2]\n",
      " [ 0 17  3  0  5]\n",
      " [ 0  7  7  0  7]\n",
      " [ 0  4  4  2 11]]\n",
      "Weighted Confusion Matrix Score:  926\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.3 s\n",
      "confusion matrix\n",
      " [[ 0 13  0  0  1]\n",
      " [ 0 14  5  1  1]\n",
      " [ 0 13  5  3  4]\n",
      " [ 0  5  3  2 11]\n",
      " [ 0  2  4  0 14]]\n",
      "Weighted Confusion Matrix Score:  973\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.62 s\n",
      "confusion matrix\n",
      " [[10  0  0  0  3]\n",
      " [ 8  0  3  1  9]\n",
      " [ 6  0 10  0  9]\n",
      " [ 7  0  3  0 11]\n",
      " [ 1  0  1  1 17]]\n",
      "Weighted Confusion Matrix Score:  1194\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.1 s\n",
      "confusion matrix\n",
      " [[ 4  8  1  0  0]\n",
      " [ 2 10  7  0  2]\n",
      " [ 0  6  9  2  8]\n",
      " [ 0  2 10  2  7]\n",
      " [ 0  0  2  0 18]]\n",
      "Weighted Confusion Matrix Score:  1010\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.2 s\n",
      "confusion matrix\n",
      " [[11  0  2  0  0]\n",
      " [18  0  3  0  0]\n",
      " [16  0  6  1  2]\n",
      " [ 5  0 12  1  2]\n",
      " [ 4  0  9  0  7]]\n",
      "Weighted Confusion Matrix Score:  949\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.1 s\n",
      "confusion matrix\n",
      " [[ 1 10  2  0  0]\n",
      " [ 0  9 11  0  0]\n",
      " [ 0 10 14  0  1]\n",
      " [ 0  7 13  0  0]\n",
      " [ 0  1 14  0  5]]\n",
      "Weighted Confusion Matrix Score:  737\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/75"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.68 s\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 1  0 19  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 19  0  1]\n",
      " [ 0  0 18  0  2]]\n",
      "Weighted Confusion Matrix Score:  713\n"
     ]
    }
   ],
   "source": [
    "vals = {'n_hidden': 150, \n",
    "         'C':0.002, 'epochs':75, 'eta':0.001, \n",
    "         'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "         'shuffle':True,'random_state':1, \n",
    "           'nonlinearity': \"relu\"}\n",
    "\n",
    "relu_performances = []\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "            print(\"---------------------------------\")\n",
    "\n",
    "            X_train = (X[train_indices])\n",
    "            y_train = y[train_indices]\n",
    "\n",
    "            X_test = (X[test_indices])\n",
    "            y_test = y[test_indices]\n",
    "\n",
    "            nn_long_sigmoid = TLPGaussianInitial(**vals)\n",
    "\n",
    "            #%time nn_long_sigmoid.fit(X_train, y_train, print_progress=1, XY_test=(X_test,y_test))\n",
    "            %time nn_long_sigmoid.fit(X_train, y_train, print_progress=1)\n",
    "            y_hat = nn_long_sigmoid.predict(X_test) # get test set precitions\n",
    "\n",
    "            # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "            acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "    #         lr_clf_accuracies.append(acc)\n",
    "    #         cost_accuracies.append([acc])\n",
    "\n",
    "            conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "#             print(vals)\n",
    "#                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "#                     plt.show()\n",
    "            print(\"confusion matrix\\n\",conf)\n",
    "            score = get_confusion_costTot(conf, cost_matrix)\n",
    "            print(\"Weighted Confusion Matrix Score: \", score)\n",
    "            relu_performances.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26065.03632068634\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAFyCAYAAAAnENp+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncjBiZmZmjXIwYmZmZo36AjzZXmlkomEqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac688fc390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac6889ac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([sk_performances,custom_performances, relu_performances])\n",
    "plt.title(\"Comparing Generalization Perfomances Including Relu\")\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Generalization Performances')\n",
    "plt.xticks([1,2, 3],['SKL','OURS', 'Our Relu'])\n",
    "plt.figure()\n",
    "print((time.time() -st)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKL even outperforms our Relu impleentation. Go SKL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
